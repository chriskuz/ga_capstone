{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdsitestconda48790fb83d3f473c989768c98a666b4b",
   "display_name": "Python 3.7.6 64-bit ('DSI_test': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Airline Prices\n",
    "By: Chirstopher Kuzemka : [Github](https://git.generalassemb.ly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Aviation is one of the largest industries dominating our global market today. Commercial aviation has made it possible for people to connect with each other in ways that may have been unimaginable over a century ago. However, a lot of thought must be put into the FAA standards and routes that modern planes must make today to make such connections possible.\n",
    "\n",
    "Consider the case example where a startup airliner, known as \"Kruze\", wants to establish itself as a top competitor against existing airliners today. A part of this startup process focuses on understanding the costs that will come into play when managing flights. Our job as data scientists today is to help Kruze determine the minimum threshold cost the airliner must charge their passengers on a ticket class basis in order to break even with a profit. To do this, we are going to use existing flight routes (velocity and altitude data), existing data on jet fuel pricing, and existing flight ticket prices (as a prediction) to help us create a supervised learning model. \n",
    "\n",
    "To start, we will approach the project with the intention of expressing a minimum proof of concept. With such introduction, we will make some limitations to our study and decrease the potential for scope increase by:\n",
    "\n",
    "- conducting an idealized thermal jet propulsion cycle for feature engineering purposes (focusing on an open Brayton cycle in particular)\n",
    "- analyzing flight route data across the U.S. domestically; choosing up to 3 routes of varying sizes and suggesting their reverse flight paths as data inputs as well. \n",
    "    - **Houston, TX** to **Los Angeles, CA** (IAH - LAX)\n",
    "    - **New York City, NY** to **Miami, FL** (JFK - MIA)\n",
    "    - **Portland, WA** to **Chicago, IL** (PDX - ORD)\n",
    "- assuming air to be treated as an ideal gas\n",
    "- assuming operating engine conditions to be steady state\n",
    "- assuming kinetic energy and potential energy to be negligible in our system, except at inlet and exit conditioins of jet engine itself\n",
    "- assuming atmospheric temperature, pressure, and air density to be an averaged value between 0 and 15,000 meters altitude\n",
    "- assuming data incorporating head or tail wind effects to be negligible\n",
    "- assuming passenger weight to be negligible\n",
    "- assuming external costs from the study (including food/maintenance/crew salary) to be negligible\n",
    "- using price data from future flights as opposed to previous flights as previous flight pricing is not readily available\n",
    "\n",
    "\n",
    "All current assumptions labeled are set to allow us to achieve (or attempt to achieve) our goal within a certain time frame, as Kruze is requiring an answer from us quickly! With this in mind, we will consider discussing how such assumptions can contribute to any error throughout our study, as well as remind ourselves that integrating negated features for future work may actually be very beneficial to us in achieveing a stronger prediction. Conducting an idealized thermal engine analysis will help us understand the average power output of a given plane's engines throughout different phases of its flight. Routes chosen throughout a variety of times and seasons will also help us determine how such elements play a role in pricing. Finally, some plane specifications (including aircraft type, number of seats it supports, as well as type/number of engines) will allow us to consider any extra technical factors for ticket pricing. \n",
    "\n",
    "As we are working with what is considerred to be a continuous variable, we will analyze common price trends utilizing a supervised regression model, such as Linear Regression, Logistic Regression, SVR, AdaBoosting Regression, Gradient Boosting Regression, KNNRegression, and Naive Bayes Regression. We will ultimately be using the Mean Absolute Error against our predictions to help us gauge how well our selected model predicts the price and discuss what issues may be observed from the limitations of this study.\n",
    "\n",
    "\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "## Table of Contents\n",
    "[1.00 Data Loading](#1.00-Data-Loading)\n",
    "\n",
    "[2.00 Superficial Analysis and History](#2.00-Superficial-Analysis-and-History)\n",
    "\n",
    "- [2.01 Quick Check](#2.01-Quick-Check)\n",
    "\n",
    "- [2.02 Data Documentation Exploration](#2.02-Data-Documentation-Exploration)\n",
    "\n",
    "[3.00 Data Cleaning](#3.00-Data-Cleaning)  \n",
    "\n",
    "[4.00 Exploratory Data Analysis and Visualization](#4.00-Exploratory-Data-Analysis-and-Visualization)\n",
    "\n",
    "[5.00 Machine Learning Modeling and Visulalization](#5.00-Machine-Learning-Modeling-and-Visulalization)\n",
    "\n",
    "- [3.01 Model Preparation](#3.01-Model-Preparation)\n",
    "\n",
    "- [3.02 Modeling](#3.02-Modeling)\n",
    "\n",
    "- [3.03 Model Selection](#3.03-Model-Selection)\n",
    "\n",
    "- [3.04 Model Evaluation](#3.04-Model-Evaluation)\n",
    "\n",
    "[6.00 Conclusions](#6.00-Conclusions)\n",
    "\n",
    "[7.00 Sources and References](#7.00-Sources-and-References)\n",
    "\n",
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.00 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\nBad key \"text.kerning_factor\" on line 4 in\n/Users/ChristopherKuzemka/opt/anaconda3/envs/DSI_test/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\nYou probably need to get an updated matplotlibrc file from\nhttps://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\nor from the matplotlib source distribution\n"
    }
   ],
   "source": [
    "import pandas as pd #imports the pandas package\n",
    "import numpy as np #imports the numpy package\n",
    "import matplotlib.pyplot as plt #imports the matplotlib plotting package\n",
    "import seaborn as sns #imports the seaborn package\n",
    "\n",
    "import json #imports the json package\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.01 Flight Tracking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_flights = pd.read_csv('../data/current_flights.csv') #reads the current_flights csv\n",
    "flight_combinations = pd.read_csv('../data/flight_combinations.csv') #reads the flight_combinations csv\n",
    "flight_schedules = pd.read_csv('../data/flight_schedules.csv') #reads the flight_schedules csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.02 Pricing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021 = pd.read_csv('../data/2021_monthly_pricing2.csv') #reads the 2021_monthly_pricing csv\n",
    "june2020_to_december2020_monthlyprice = pd.read_csv('../data/june2020_to_december2020_monthlyprice.csv') #reads the 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.03 Additional Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_checkpoint_travel = pd.read_excel('../data/tsa_checkpoint_travel.xlsx', sheet_name = 'Sheet1', index_col = None, usecols = 'A:C') #reads the tsa_checkpoint_travel xlsx\n",
    "tsa_confirmed_cases = pd.read_excel('../data/tsa_confirmed_cases.xlsx', sheet_name = 'Sheet1', index_col = None, usecols=  'A:E') #reads the tsa_confirmed_cases xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.00 Data Data Cleaning and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.01 Quick Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_check(dataframe):\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The head of your input dataframe is dataframe is:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.head()) #checks the head of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The tail of your input dataframe is:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.tail()) #checks the tail of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The shape of the dataframe is {dataframe.shape[0]} rows and {dataframe.shape[1]} columns.\") #checks the shape of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows whether there exist nulls in our dataframe or not:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.isnull().any()) #checks the null status of the current_flights dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows the useful information to be aware of when exploring this input dataframe:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.info()) #checks the null status of the current_flights dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function is created to conveniently conduct a quick check on the dataframe for the reader/user. Through it, we will able to see the __head__, __tail__, __shape__, __null presence__, and __important dataframe information__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Flights Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0                      faFlightID   ident prefix  type  suffix  \\\n0           0       DAL333-1590465975-fa-0008  DAL333    NaN  A321     NaN   \n1           1  KLM601-1590468354-airline-0005  KLM601    NaN  B77W     NaN   \n2           2       VIR607-1590664542-ed-0002  VIR607    NaN  B789     NaN   \n3           3       DAL702-1590465982-fa-0006  DAL702    NaN  A321     NaN   \n4           4  ACA572-1590468353-airline-0278  ACA572    NaN  A319     NaN   \n\n  origin destination  timeout   timestamp  ...  lowLatitude  highLongitude  \\\n0   KATL        KLAX        0  1590716390  ...     32.94676      -84.44664   \n1   EHAM        KLAX        0  1590711509  ...     33.95142        4.71741   \n2   EGLL        KLAX        0  1590711368  ...     33.95091       -0.39345   \n3   KATL        KLAX        0  1590709847  ...     33.64682      -84.44602   \n4   CYVR        KLAX        0  1590706589  ...     33.95183     -118.17553   \n\n   highLatitude  groundspeed  altitude  heading  altitudeStatus  updateType  \\\n0      33.70005          448       300      264             NaN           A   \n1      66.06976          130         1      263             NaN           A   \n2      66.09780          101         1      263             NaN           A   \n3      35.52932          117         1      263             NaN           A   \n4      49.18984          109         1      263             NaN           A   \n\n   altitudeChange                                          waypoints  \n0               D  33.64 -84.43 33.68 -84.28 33.81 -84.28 33.81 -...  \n1               D  52.31 4.76 53.02 2.53 53.06 2.46 53.2 1.53 53....  \n2               D  51.48 -0.46 51.56 -0.59 51.62 -0.68 51.7 -0.79...  \n3               D  33.64 -84.43 33.68 -84.28 33.79 -85 33.81 -85....  \n4               D  49.19 -123.18 49.12 -123.26 49.12 -123.27 49.0...  \n\n[5 rows x 26 columns]\n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                       faFlightID    ident prefix  type  \\\n100         100  EDV4708-1590468354-airline-0112  EDV4708    NaN  CRJ9   \n101         101        ABW341-1590583043-eb-0002   ABW341    NaN  B744   \n102         102  DLH8176-1590641113-airline-0180  DLH8176    NaN  B772   \n103         103  CLX8626-1590641113-airline-0361  CLX8626    NaN  B744   \n104         104  DLH8172-1590641113-airline-0177  DLH8172    NaN  MD11   \n\n     suffix origin destination  timeout   timestamp  ...  lowLatitude  \\\n100     NaN   KAGS        KATL        0  1590664135  ...     33.19607   \n101     NaN   EBLG        KATL        0  1590631398  ...     33.53333   \n102     NaN   EDDF        KATL        0           0  ...    200.00000   \n103     NaN   ELLX        KATL        0           0  ...    200.00000   \n104     NaN   EDDF        KATL        0           0  ...    200.00000   \n\n     highLongitude  highLatitude  groundspeed  altitude  heading  \\\n100      -81.97964      33.63222          126        10       91   \n101        5.56940      54.10380          132         9       90   \n102     -200.00000    -200.00000            0         0        0   \n103     -200.00000    -200.00000            0         0        0   \n104     -200.00000    -200.00000            0         0        0   \n\n     altitudeStatus  updateType  altitudeChange  \\\n100             NaN           A               D   \n101                           A               D   \n102             NaN         NaN             NaN   \n103             NaN         NaN             NaN   \n104             NaN         NaN             NaN   \n\n                                             waypoints  \n100  33.37 -81.96 33.39 -82.03 33.39 -82.04 33.38 -...  \n101  50.64 5.44 50.69 5.24 50.73 5.08 50.78 4.89 50...  \n102                                                NaN  \n103                                                NaN  \n104                                                NaN  \n\n[5 rows x 26 columns]\n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 105 rows and 26 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0           False\nfaFlightID           False\nident                False\nprefix                True\ntype                  True\nsuffix                True\norigin               False\ndestination          False\ntimeout              False\ntimestamp            False\ndepartureTime        False\nfirstPositionTime    False\narrivalTime          False\nlongitude            False\nlatitude             False\nlowLongitude         False\nlowLatitude          False\nhighLongitude        False\nhighLatitude         False\ngroundspeed          False\naltitude             False\nheading              False\naltitudeStatus        True\nupdateType            True\naltitudeChange        True\nwaypoints             True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 105 entries, 0 to 104\nData columns (total 26 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Unnamed: 0         105 non-null    int64  \n 1   faFlightID         105 non-null    object \n 2   ident              105 non-null    object \n 3   prefix             1 non-null      object \n 4   type               103 non-null    object \n 5   suffix             0 non-null      float64\n 6   origin             105 non-null    object \n 7   destination        105 non-null    object \n 8   timeout            105 non-null    int64  \n 9   timestamp          105 non-null    int64  \n 10  departureTime      105 non-null    int64  \n 11  firstPositionTime  105 non-null    int64  \n 12  arrivalTime        105 non-null    int64  \n 13  longitude          105 non-null    float64\n 14  latitude           105 non-null    float64\n 15  lowLongitude       105 non-null    float64\n 16  lowLatitude        105 non-null    float64\n 17  highLongitude      105 non-null    float64\n 18  highLatitude       105 non-null    float64\n 19  groundspeed        105 non-null    int64  \n 20  altitude           105 non-null    int64  \n 21  heading            105 non-null    int64  \n 22  altitudeStatus     31 non-null     object \n 23  updateType         90 non-null     object \n 24  altitudeChange     90 non-null     object \n 25  waypoints          89 non-null     object \ndtypes: float64(7), int64(9), object(10)\nmemory usage: 21.5+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(current_flights) #performs a quick check on the current_flights dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 105 rows and 26 columns. Not all columns are revealed in the head and tail of the function. \n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- Most of the values in our dataframe are numerical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Combinations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0 origin destination  0\n0           0   CYHM        KJFK  1\n1           1   CYUL        KORD  1\n2           2   CYVR        KLAX  1\n3           3   CYYZ        KIAH  2\n4           4   CYYZ        KJFK  1\n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Unnamed: 0 origin destination  0\n55          55   KBUR        KPDX  1\n56          56   KBWI        KPDX  1\n57          57   KCVG        KPDX  1\n58          58   KCVO        KPDX  2\n59          59   KDEN        KPDX  3\n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 60 rows and 4 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0     False\norigin         False\ndestination    False\n0              False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 60 entries, 0 to 59\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   Unnamed: 0   60 non-null     int64 \n 1   origin       60 non-null     object\n 2   destination  60 non-null     object\n 3   0            60 non-null     int64 \ndtypes: int64(2), object(2)\nmemory usage: 2.0+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(flight_combinations) #performs a quick check on the flight combinations dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Takeaways form the above output:\n",
    "\n",
    "- There is an `Unnamed: 0` column which does not need to be included. \n",
    "\n",
    "- The dataframe is 60 rows and has 4 columns. \n",
    "\n",
    "- The column named `0` is the final column and shows the frequency of the flight combination shown in the dataframe. \n",
    "\n",
    "- There are no nulls. \n",
    "\n",
    "- All of the values are numerical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Schedules Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0    ident actual_ident  departuretime  arrival_time origin  \\\n0           0  UAL4282      ASQ4282     1588330800    1588340820   CYUL   \n1           1  ACA7591      AC27591     1588335000    1588343880   CYUL   \n2           2  UAL8371      AC27591     1588335000    1588343880   CYUL   \n3           3  UAL4245      ASQ4245     1588341060    1588351080   CYUL   \n4           4  UAL8481      AC27595     1588353300    1588362000   CYUL   \n\n  destination aircrafttype                                       meal_service  \\\n0        KORD         E75L    Business: Refreshments / Economy: Food for sale   \n1        KORD         E75L  Business: Breakfast / Economy: Breakfast, Food...   \n2        KORD         E75L       Business: Breakfast / Economy: Food for sale   \n3        KORD         E75L    Business: Refreshments / Economy: Food for sale   \n4        KORD         E75L            Business: Meal / Economy: Food for sale   \n\n   seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n0                  0                    12                 58  \n1                  0                    12                 64  \n2                  0                    12                 64  \n3                  0                    12                 58  \n4                  0                    12                 64  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n      Unnamed: 0    ident actual_ident  departuretime  arrival_time origin  \\\n5818        5818   UAL464          NaN     1590514200    1590523860   KDEN   \n5819        5819   SWA378          NaN     1590520500    1590529500   KDEN   \n5820        5820  DLH9070       UAL393     1590539460    1590549120   KDEN   \n5821        5821   UAL393          NaN     1590539460    1590549120   KDEN   \n5822        5822   SWA993          NaN     1590544800    1590554400   KDEN   \n\n     destination aircrafttype                                  meal_service  \\\n5818        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5819        KPDX         B738                              Economy: No meal   \n5820        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5821        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5822        KPDX         B738                              Economy: No meal   \n\n      seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n5818                  0                    12                114  \n5819                  0                     0                175  \n5820                  0                    12                114  \n5821                  0                    12                114  \n5822                  0                     0                175  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 5823 rows and 12 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0              False\nident                   False\nactual_ident             True\ndeparturetime           False\narrival_time            False\norigin                  False\ndestination             False\naircrafttype             True\nmeal_service             True\nseats_cabin_first       False\nseats_cabin_business    False\nseats_cabin_coach       False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5823 entries, 0 to 5822\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   Unnamed: 0            5823 non-null   int64 \n 1   ident                 5823 non-null   object\n 2   actual_ident          4639 non-null   object\n 3   departuretime         5823 non-null   int64 \n 4   arrival_time          5823 non-null   int64 \n 5   origin                5823 non-null   object\n 6   destination           5823 non-null   object\n 7   aircrafttype          5373 non-null   object\n 8   meal_service          5429 non-null   object\n 9   seats_cabin_first     5823 non-null   int64 \n 10  seats_cabin_business  5823 non-null   int64 \n 11  seats_cabin_coach     5823 non-null   int64 \ndtypes: int64(6), object(6)\nmemory usage: 546.0+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(flight_schedules) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 5823 rows and 12 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have an even split of numerical and string values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Pricing 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0 Quotes Places Carriers  \\\n0           0     []     []       []   \n1           1     []     []       []   \n2           2     []     []       []   \n3           3     []     []       []   \n4           4     []     []       []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n715         715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716         716                                                 []   \n717         717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718         718                                                 []   \n719         719                                                 []   \n\n                                                Places  \\\n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies ValidationErrors  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 720 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 720 entries, 0 to 719\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        720 non-null    int64 \n 1   Quotes            696 non-null    object\n 2   Places            696 non-null    object\n 3   Carriers          696 non-null    object\n 4   Currencies        696 non-null    object\n 5   ValidationErrors  24 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 33.9+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(monthly_pricing_2021) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways from the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 720 rows and 7 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### June 2020 To December 2020 Monthly Prices Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0                                             Quotes  \\\n0           0                                                 []   \n1           1  [{'QuoteId': 1, 'MinPrice': 327.0, 'Direct': F...   \n2           2  [{'QuoteId': 1, 'MinPrice': 353.0, 'Direct': F...   \n3           3                                                 []   \n4           4                                                 []   \n\n                                              Places  \\\n0                                                 []   \n1  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n2  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n3                                                 []   \n4                                                 []   \n\n                                   Carriers  \\\n0                                        []   \n1  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n2  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n3                                        []   \n4                                        []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n415         415  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n416         416  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n417         417  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n418         418  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n419         419  [{'QuoteId': 1, 'MinPrice': 63.0, 'Direct': Tr...   \n\n                                                Places  \\\n415  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n416  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n417  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n418  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n419  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n415  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n416  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n417  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n418  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n419  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n\n                                            Currencies ValidationErrors  \n415  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n416  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n417  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n418  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n419  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 420 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 420 entries, 0 to 419\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        420 non-null    int64 \n 1   Quotes            406 non-null    object\n 2   Places            406 non-null    object\n 3   Carriers          406 non-null    object\n 4   Currencies        406 non-null    object\n 5   ValidationErrors  14 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 19.8+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(june2020_to_december2020_monthlyprice) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 5823 rows and 6 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSA Checkpoint Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n        Date  Total Traveler Throughput  Total Traveler Throughput.1\n0        NaT                        NaN  (1 Year Ago - Same Weekday)\n1 2020-05-26                   264843.0                      2453649\n2 2020-05-25                   340769.0                      2512237\n3 2020-05-24                   267451.0                      2070716\n4 2020-05-23                   253190.0                      2124825\n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n         Date  Total Traveler Throughput Total Traveler Throughput.1\n83 2020-03-05                  2130015.0                     2402692\n84 2020-03-04                  1877401.0                     2143619\n85 2020-03-03                  1736393.0                     1979558\n86 2020-03-02                  2089641.0                     2257920\n87 2020-03-01                  2280522.0                     2301439\n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 88 rows and 3 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nDate                            True\nTotal Traveler Throughput       True\nTotal Traveler Throughput.1    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 88 entries, 0 to 87\nData columns (total 3 columns):\n #   Column                       Non-Null Count  Dtype         \n---  ------                       --------------  -----         \n 0   Date                         87 non-null     datetime64[ns]\n 1   Total Traveler Throughput    87 non-null     float64       \n 2   Total Traveler Throughput.1  88 non-null     object        \ndtypes: datetime64[ns](1), float64(1), object(1)\nmemory usage: 2.2+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(tsa_checkpoint_travel) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- There is a `Date` column not currently set as the index of the dataframe. We will consider making the `Date` column the index. \n",
    "\n",
    "- The first row seems to contain header information. We will append the appropriate values into the header. \n",
    "\n",
    "- Our dataframe is 88 rows and 3 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have an even split of string, float, and datetime values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSA Confirmed Cases Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                          Airport  Total Confirmed Cases  \\\n0               ACY - Atlantic City International                      1   \n1                        AIA - Alliance Municipal                      1   \n2                      ALW - Walla Walla Regional                      1   \n3       AMA - Rick Husband Amarillo International                      1   \n4  ATL - Hartsfield-Jackson Atlanta International                     17   \n\n   TSA Screening Officers  Non-Screening Employees  \\\n0                     1.0                      NaN   \n1                     1.0                      NaN   \n2                     1.0                      NaN   \n3                     1.0                      NaN   \n4                    16.0                      1.0   \n\n  Last work date of most recent screening officer confirmed case  \n0                                         2020-05-16              \n1                                         2020-05-19              \n2                                         2020-03-24              \n3                                         2020-05-02              \n4                                         2020-03-18              \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                  Airport  Total Confirmed Cases  \\\n73  STL - St. Louis Lambert International                      1   \n74                     STT - Cyril E King                      1   \n75             TLH - Tallahassee Regional                      1   \n76                   TOL - Toledo Express                      2   \n77              TPA - Tampa International                      2   \n\n    TSA Screening Officers  Non-Screening Employees  \\\n73                     1.0                      NaN   \n74                     1.0                      NaN   \n75                     1.0                      NaN   \n76                     2.0                      NaN   \n77                     1.0                      1.0   \n\n   Last work date of most recent screening officer confirmed case  \n73                                         2020-04-27              \n74                                         2020-03-13              \n75                                         2020-05-04              \n76                                         2020-04-06              \n77                                         2020-04-08              \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 78 rows and 5 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nAirport                                                           False\nTotal Confirmed Cases                                             False\nTSA Screening Officers                                             True\nNon-Screening Employees                                            True\nLast work date of most recent screening officer confirmed case     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 78 entries, 0 to 77\nData columns (total 5 columns):\n #   Column                                                          Non-Null Count  Dtype         \n---  ------                                                          --------------  -----         \n 0   Airport                                                         78 non-null     object        \n 1   Total Confirmed Cases                                           78 non-null     int64         \n 2   TSA Screening Officers                                          76 non-null     float64       \n 3   Non-Screening Employees                                         22 non-null     float64       \n 4   Last work date of most recent screening officer confirmed case  76 non-null     datetime64[ns]\ndtypes: datetime64[ns](1), float64(2), int64(1), object(1)\nmemory usage: 3.2+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(tsa_confirmed_cases) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The data columns are separated above with a `\\`.\n",
    "\n",
    "- Our dataframe is 78 rows and 5 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have string, float, and datetime values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.02 Data Documentation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the \"Flight Data\"?\n",
    "\n",
    "The \"Flight Data\" is referring to the the dataframes showcasing the current flights (`current_flights`), flight combinations (`flight_combinations`), and flight schedules(`flight_schedules`). They each preside in the order which they were constructed, where the `current_flights` dataframe was collected first, then the `flight_combinations`, then the `flight_schedules`. All of the flight data collected stemmed from the root dataframe for this study: `current_flights`. Below are the data dictionaries for each dataframe after their cleaning process showcased in [3.00 Data Cleaning](#3.00-Data-Cleaning). The data dictionaries are to help us understand what each dataframe's value represents as the airline language can be non-intuitive to understand. Some of the values are also representative of API utilized to gather the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How was the Flight Data Gathered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Biases Play a Role in the Data? What Compromises were Made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Price Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How was the Price Data Gathered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Biases Play a Role in the Data? What Compromises were Made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the Other Relevant Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How was the Other Relevant Data Gathered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Biases Play a Role in the Data? What Compromises were Made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.00 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.01 Flight Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_analysis(dataframe):\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows whether there exist nulls in our dataframe or not:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.isnull().any()) #checks the null status of the current_flights dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows the mean of nulls existing in a dataframe:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.isnull().mean().sort_values(ascending = False)) #checks the mean nulls in each column of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The column with the most nulls is the '{dataframe.isnull().mean().sort_values(ascending = False).index[0]}' column with a null percentage of {dataframe.isnull().mean().sort_values(ascending = False).iloc[0]*100}%.\") #shows the highest percentage of nulls in the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    highest_null_mask = dataframe[str(dataframe.isnull().mean().sort_values(ascending = False).index[0])].isnull() == True #creates a mask of showcasing the highest nulled column in the dataframe\n",
    "    print(\"The below shows the most masked null dataframe for more clear understanding:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe[highest_null_mask]) #shows the highest null-dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    anti_highest_null_mask = dataframe[str(dataframe.isnull().mean().sort_values(ascending = False).index[0])].isnull() == False #creates a mask of showcasing the dataframe without the highest nulled column\n",
    "    print(\"The below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe[anti_highest_null_mask]) #shows the highest anti-null dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.02 Price Data\n",
    "\n",
    "A plethora of price data was collected using the Skyscanner API. However, due to complications, some prices were found to be null for certain dates. With such limitations, lots of other data were collected to help us fill in the gaps for the missing values. We will explore both dataframes for pricing to help us analyze appropriate prices per flight. To start our cleaning process, we will re-state our `quick_check` function and re-state our key takeaways from earlier in the study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0 Quotes Places Carriers  \\\n0           0     []     []       []   \n1           1     []     []       []   \n2           2     []     []       []   \n3           3     []     []       []   \n4           4     []     []       []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n715         715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716         716                                                 []   \n717         717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718         718                                                 []   \n719         719                                                 []   \n\n                                                Places  \\\n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies ValidationErrors  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 720 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 720 entries, 0 to 719\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        720 non-null    int64 \n 1   Quotes            696 non-null    object\n 2   Places            696 non-null    object\n 3   Carriers          696 non-null    object\n 4   Currencies        696 non-null    object\n 5   ValidationErrors  24 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 33.9+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(monthly_pricing_2021) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways from the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 720 rows and 7 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking the 2021 Monthly Pricing Dataframe and Null Analysis\n",
    "\n",
    "Due to the Skyscanner's method of data scraping, our data is nested inside of dictionaries. We are going to need to clean up the dictionaries and most likely export a lot more hidden data from these dictionaries. We are prepared to create more dataframes out of these dictionaries. To make dictionary unpacking process more efficient, we are also going to have to perform a null analysis on all of the data so help us recognize any `NaNs` in our dataframe. Once such `NaNs` are recognized, we can determine what would be the most appropriate action to substitute a value for such `NaNs` OR completely eliminate them entirely based on their importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to drop the `Unnamed: 0` column through the above defined function to ease our dataframe cleaning process across multiple dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drops the Unnamed column in the dataframe\n",
    "def drop_unnamed(dataframe):\n",
    "    dataframe.drop(columns = 'Unnamed: 0', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_unnamed(monthly_pricing_2021) #drops the unnamed column in the 2021 dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze how many nulls there are from the `monthly_pricing_2021` dataframe to start. This will give us some idea about the dataframe in particular and help us determine what necessary steps are needed to help us analyze our most important columns: the `Quotes` column. This will also help pave the way for handling of the similar dataframe, `june2020_to_december_2020`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes              True\nPlaces              True\nCarriers            True\nCurrencies          True\nValidationErrors    True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nValidationErrors    0.966667\nCurrencies          0.033333\nCarriers            0.033333\nPlaces              0.033333\nQuotes              0.033333\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'ValidationErrors' column with a null percentage of 96.66666666666667%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716                                                 []   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718                                                 []   \n719                                                 []   \n\n                                                Places  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies ValidationErrors  \n0    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n..                                                 ...              ...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n\n[696 rows x 5 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Quotes Places Carriers Currencies  \\\n624    NaN    NaN      NaN        NaN   \n625    NaN    NaN      NaN        NaN   \n626    NaN    NaN      NaN        NaN   \n627    NaN    NaN      NaN        NaN   \n628    NaN    NaN      NaN        NaN   \n629    NaN    NaN      NaN        NaN   \n630    NaN    NaN      NaN        NaN   \n631    NaN    NaN      NaN        NaN   \n632    NaN    NaN      NaN        NaN   \n633    NaN    NaN      NaN        NaN   \n634    NaN    NaN      NaN        NaN   \n635    NaN    NaN      NaN        NaN   \n696    NaN    NaN      NaN        NaN   \n697    NaN    NaN      NaN        NaN   \n698    NaN    NaN      NaN        NaN   \n699    NaN    NaN      NaN        NaN   \n700    NaN    NaN      NaN        NaN   \n701    NaN    NaN      NaN        NaN   \n702    NaN    NaN      NaN        NaN   \n703    NaN    NaN      NaN        NaN   \n704    NaN    NaN      NaN        NaN   \n705    NaN    NaN      NaN        NaN   \n706    NaN    NaN      NaN        NaN   \n707    NaN    NaN      NaN        NaN   \n\n                                      ValidationErrors  \n624  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n625  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n626  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n627  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n628  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n629  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n630  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n631  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n632  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n633  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n634  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n635  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n696  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n697  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n698  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n699  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n700  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n701  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n702  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n703  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n704  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n705  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n706  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n707  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n"
    }
   ],
   "source": [
    "null_analysis(monthly_pricing_2021) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, our `ValidationErrors` column contains the most nulls in our dataframe. With respect to the context of our study, keeping these `ValidationErrors` column is unnecessary as it is only an indicator for a successful query search. We will drop it from the dataframe. Before doing so, it would best to also interpret the pecentage of `ValidationErrors` nulls and comapre against the percentage nulls of the rest of the columns in our dataframe. The rest of our dataframe is presenting approximately 3.3% nulls. Through the final print statement from the above output of the dataframe, we notice that the dataframe showing values for true `ValidationErrors` is expressing nulls across the entire rows of such data. We can confidently state that the data rest of the dataframe showing nulls are missing not at random ([MNAR](https://www.theanalysisfactor.com/missing-data-mechanism/)) in this instance. We cannot identify what is triggering the validation errors in the first place through a large data scrape, but we do know the validation errors to be present for every row of `NaNs`; we know the two are related and can confidently state that for every true instance of a validation error, we can expect a row to be empty. \n",
    "\n",
    "In summary, we know that there is no need to keep the `ValidationErrors` in our study. With entire rows missing form the dataframe, we will not be able to make any meaningful identification for the missing data or find a way to impute such values. Therefore, we will drop such rows. The cost of damage for this study is minimal with only a loss of approximately 3.3% of our values. Any further errors recognized will consider this dataframe drop as a culprit, during the mass dataframe concatenation conducted in a later section (partciularly combatting an instance where a flight combination may not be read for the study).\n",
    "\n",
    "To efficiently do this, we will drop nulls across the most improtant target feature column which will shave approximately 3.3 percent of our dataframe. We will then drop the `ValidationErrors` column.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.dropna(subset = ['Quotes'], inplace = True) #drops the nulls in the dataframe pivoting off the quotes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.drop(columns = 'ValidationErrors', inplace = True) #drops the validation errors column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes        False\nPlaces        False\nCarriers      False\nCurrencies    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nCurrencies    0.0\nCarriers      0.0\nPlaces        0.0\nQuotes        0.0\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'Currencies' column with a null percentage of 0.0%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nEmpty DataFrame\nColumns: [Quotes, Places, Carriers, Currencies]\nIndex: []\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716                                                 []   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718                                                 []   \n719                                                 []   \n\n                                                Places  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies  \n0    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n1    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n2    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n3    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n4    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[696 rows x 4 columns]\n"
    }
   ],
   "source": [
    "null_analysis(monthly_pricing_2021) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conducting a second null_analysis on the dataframe shows that nulls no longer exist in a manner that is recognized by python. However, this does not mean we aren't missing any data. Through some of the above output, we can intuitively recognize that we are indeed missing some quotes through successful query searches. Let's analyze why python is misinterpreting such nulls. To do this, we will analyze an \"empty\" element in `monthly_pricing_2021[Quotes]` to see what python is recognizing, as well as a \"filled\" element.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "An empty element is: <class 'str'>\n- - - - - - - - - - - - - - - - - - - -\nAn empty element is: <class 'str'>\n"
    }
   ],
   "source": [
    "print(f\"An empty element is: {type(monthly_pricing_2021.loc[0, 'Quotes'])}\") #prints the type of an \"empty\" elements\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print(f\"An empty element is: {type(monthly_pricing_2021.loc[715, 'Quotes'])}\") #prints the type of a \"filled\" element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above outputs, we can see that each element is being recognized as a string. This means the perceived \"empty\" elements are expressing a True Boolean state output. We will first replace such strings \"empty\" strings to proper `NaNs` and perform another null analysis plus drop such nulls. Then we will convert leftover \"filled\" strings to their perceived appropriate outputs with a function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021['Quotes'] = monthly_pricing_2021['Quotes'].replace(\"[]\", np.nan) #replaces the \"empty lists\" with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes         True\nPlaces        False\nCarriers      False\nCurrencies    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes        0.841954\nCurrencies    0.000000\nCarriers      0.000000\nPlaces        0.000000\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'Quotes' column with a null percentage of 84.19540229885058%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Quotes Places Carriers                                         Currencies\n0      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n1      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n2      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n3      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n4      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n..     ...    ...      ...                                                ...\n713    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n714    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n716    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n718    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n719    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n\n[586 rows x 4 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n18   [{'QuoteId': 1, 'MinPrice': 176.0, 'Direct': T...   \n24   [{'QuoteId': 1, 'MinPrice': 123.0, 'Direct': T...   \n29   [{'QuoteId': 1, 'MinPrice': 99.0, 'Direct': Tr...   \n30   [{'QuoteId': 1, 'MinPrice': 107.0, 'Direct': T...   \n31   [{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': T...   \n..                                                 ...   \n681  [{'QuoteId': 1, 'MinPrice': 351.0, 'Direct': F...   \n693  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n708  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n\n                                                Places  \\\n18   [{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...   \n24   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n29   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n30   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n31   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n..                                                 ...   \n681  [{'PlaceId': 43369, 'IataCode': 'BWI', 'Name':...   \n693  [{'PlaceId': 45623, 'IataCode': 'CVG', 'Name':...   \n708  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n18          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n24   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n29   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n30          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n31   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n..                                                 ...   \n681  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n693  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n708  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n\n                                            Currencies  \n18   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n24   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n29   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n30   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n31   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n681  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n693  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n708  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[110 rows x 4 columns]\n"
    }
   ],
   "source": [
    "null_analysis(monthly_pricing_2021) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.dropna(subset = ['Quotes'], inplace = True) #drops the recognized nulls in the Quotes column to have an effect across the entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts the strings as literal expressions\n",
    "def as_lit_for_json(dataframe):\n",
    "    for column in dataframe.columns:\n",
    "        dataframe[column] = dataframe[column].apply(lambda element: ast.literal_eval(element)) #utilizes the ast package\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Quotes</th>\n      <th>Places</th>\n      <th>Carriers</th>\n      <th>Currencies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 176.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}]</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 123.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 99.0, 'Direct': Tr...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 107.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}]</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 351.0, 'Direct': F...</td>\n      <td>[{'PlaceId': 43369, 'IataCode': 'BWI', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>693</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...</td>\n      <td>[{'PlaceId': 45623, 'IataCode': 'CVG', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>708</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...</td>\n      <td>[{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...</td>\n      <td>[{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...</td>\n      <td>[{'CarrierId': 851, 'Name': 'Alaska Airlines'}...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>110 rows  4 columns</p>\n</div>",
      "text/plain": "                                                Quotes  \\\n18   [{'QuoteId': 1, 'MinPrice': 176.0, 'Direct': T...   \n24   [{'QuoteId': 1, 'MinPrice': 123.0, 'Direct': T...   \n29   [{'QuoteId': 1, 'MinPrice': 99.0, 'Direct': Tr...   \n30   [{'QuoteId': 1, 'MinPrice': 107.0, 'Direct': T...   \n31   [{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': T...   \n..                                                 ...   \n681  [{'QuoteId': 1, 'MinPrice': 351.0, 'Direct': F...   \n693  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n708  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n\n                                                Places  \\\n18   [{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...   \n24   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n29   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n30   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n31   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n..                                                 ...   \n681  [{'PlaceId': 43369, 'IataCode': 'BWI', 'Name':...   \n693  [{'PlaceId': 45623, 'IataCode': 'CVG', 'Name':...   \n708  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n18          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n24   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n29   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n30          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n31   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n..                                                 ...   \n681  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n693  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n708  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n\n                                            Currencies  \n18   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n24   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n29   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n30   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n31   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n681  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n693  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n708  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[110 rows x 4 columns]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_lit_for_json(monthly_pricing_2021) #converts the dataframe's strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect a chosen row from the dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----------------------------------------\n{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [1065], 'OriginId': 47118, 'DestinationId': 74728, 'DepartureDate': '2021-02-01T00:00:00'}, 'QuoteDateTime': '2020-06-01T13:48:00'}\n-----------------------------------------\n{'PlaceId': 47118, 'IataCode': 'DEN', 'Name': 'Denver International', 'Type': 'Station', 'SkyscannerCode': 'DEN', 'CityName': 'Denver', 'CityId': 'DENA', 'CountryName': 'United States'}\n-----------------------------------------\n{'PlaceId': 74728, 'IataCode': 'PDX', 'Name': 'Portland', 'Type': 'Station', 'SkyscannerCode': 'PDX', 'CityName': 'Portland', 'CityId': 'PDXA', 'CountryName': 'United States'}\n-----------------------------------------\n{'CarrierId': 1065, 'Name': 'Frontier Airlines'}\n-----------------------------------------\n{'Code': 'USD', 'Symbol': '$', 'ThousandsSeparator': ',', 'DecimalSeparator': '.', 'SymbolOnLeft': True, 'SpaceBetweenAmountAndSymbol': False, 'RoundingCoefficient': 0, 'DecimalDigits': 2}\n"
    }
   ],
   "source": [
    "for i in range(len(monthly_pricing_2021.loc[715])):\n",
    "    for k in range(len(monthly_pricing_2021.loc[715][i])):\n",
    "        print('-----------------------------------------')\n",
    "        print(monthly_pricing_2021.loc[715][i][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each printed element above exists within indexed row, 715 of the above dataframe. Each element is a json dictionary contained within a list. From the first element (under the `Quotes` column), all values will be considered into our new dataframe except for the `QuoteDateTime` dicitonary. \n",
    "\n",
    "For the second and third printed element (under the `Places` column), we can integrate most of the information. Keep in mind, the target dataframe will need to be integrated with the features dataframe. To do this, we will primarily utilize the `IataCode` to identify airports. \n",
    "\n",
    "The fourth printed element seems useful in that it can also provide additional airline information. This can be used to check against the flight combination airline that was originally searched. \n",
    "\n",
    "The final printed element above shows what sort of currency was returned. We are completely operating in U.S. dollars and would not require to keep such column. We will drop this column next before moving onto unpacking the dataframe. \n",
    "\n",
    "Let's drop the `Currencies` column entirely and reset the index and observe another element. This will give us a better understanding of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.drop(columns = 'Currencies', inplace = True)\n",
    "monthly_pricing_2021.reset_index(inplace = True)\n",
    "monthly_pricing_2021.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect another element in our dataframe to have a better understanding of how organiz it is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----------------------------------------\n{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [835], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-08T00:00:00'}, 'QuoteDateTime': '2020-06-02T19:46:00'}\n-----------------------------------------\n{'QuoteId': 2, 'MinPrice': 100.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [835], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-16T00:00:00'}, 'QuoteDateTime': '2020-06-02T05:41:00'}\n-----------------------------------------\n{'QuoteId': 3, 'MinPrice': 106.0, 'Direct': False, 'OutboundLeg': {'CarrierIds': [1793], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-19T00:00:00'}, 'QuoteDateTime': '2020-05-31T00:27:00'}\n-----------------------------------------\n{'QuoteId': 4, 'MinPrice': 123.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [1907], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-19T00:00:00'}, 'QuoteDateTime': '2020-05-31T00:27:00'}\n-----------------------------------------\n{'PlaceId': 65368, 'IataCode': 'LAX', 'Name': 'Los Angeles International', 'Type': 'Station', 'SkyscannerCode': 'LAX', 'CityName': 'Los Angeles', 'CityId': 'LAXA', 'CountryName': 'United States'}\n-----------------------------------------\n{'PlaceId': 96322, 'IataCode': 'YVR', 'Name': 'Vancouver International', 'Type': 'Station', 'SkyscannerCode': 'YVR', 'CityName': 'Vancouver', 'CityId': 'YVRA', 'CountryName': 'Canada'}\n-----------------------------------------\n{'CarrierId': 835, 'Name': 'Air Canada'}\n-----------------------------------------\n{'CarrierId': 1793, 'Name': 'United'}\n-----------------------------------------\n{'CarrierId': 1907, 'Name': 'WestJet'}\n"
    }
   ],
   "source": [
    "for i in range(len(monthly_pricing_2021.loc[4])):\n",
    "    for k in range(len(monthly_pricing_2021.loc[4][i])):\n",
    "        print('-----------------------------------------')\n",
    "        print(monthly_pricing_2021.loc[4][i][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see more print outputs for our new row shown at index 4. How can this be, if we dropped a column? We should bee seeing less data, no?\n",
    "\n",
    "Thoe above still showcases that we lost the unecessary currency column, but instead we are able to see a better picture of the dynamic changes in the data. In indexed row 4, there are four quotes shown with four different prices spread across three carriers. The places column seems to remain static. \n",
    "\n",
    "The focus in cleaning this data will be on generating a `quotes_2021` dataframe and storing the just the information from the Quotes column. Then we will map the `Places` information and `Carriers` information to our new quotes dataframe to finally complete our target dataframe. Such information useful to the target information can be considered as features for our feature dataframe. We do not have to worry about this being a large form of bias as we will be careful for what information we will to include (such as choosing city names).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targetframe(price_dataframe):\n",
    "    quotes = pd.DataFrame(columns = ['QuoteId', 'MinPrice', 'Direct', 'CarrierIds', 'OriginId', 'DestinationId', 'DepartureDate'])\n",
    "    places = pd.DataFrame(columns = ['PlaceId', 'IataCode', 'Name', 'CityName', 'CountryName'])\n",
    "    carriers = pd.DataFrame(columns = ['CarrierId', 'Name'])\n",
    "\n",
    "\n",
    "    ## Makes the Quotes Dataframe\n",
    "    for i in range(len(price_dataframe)):\n",
    "        for j in range(len(price_dataframe.loc[i, 'Quotes'])):\n",
    "            quoteid = price_dataframe.loc[i, 'Quotes'][j]['QuoteId']\n",
    "            minprice = price_dataframe.loc[i, 'Quotes'][j]['MinPrice']\n",
    "            direct = price_dataframe.loc[i, 'Quotes'][j]['Direct']\n",
    "            carrierid = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['CarrierIds']\n",
    "            originid = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['OriginId']\n",
    "            destinationid = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['DestinationId']\n",
    "            departuredate = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['DepartureDate']\n",
    "            \n",
    "            individual_quotes_dict = {'QuoteId':quoteid,\n",
    "                        'MinPrice': minprice,\n",
    "                        'Direct': direct,\n",
    "                        'CarrierIds': carrierid,\n",
    "                        'OriginId': originid,\n",
    "                        'DestinationId': destinationid,\n",
    "                        'DepartureDate': departuredate}\n",
    "            \n",
    "            individual_quotes_df = pd.DataFrame(individual_quotes_dict, columns = individual_quotes_dict.keys())\n",
    "            quotes = pd.concat([quotes, individual_quotes_df])\n",
    "\n",
    "    ## Makes the Places Dataframe\n",
    "    for i in range(len(price_dataframe)):\n",
    "        for j in range(len(price_dataframe.loc[i, 'Places'])):\n",
    "            placeid = price_dataframe.loc[i, 'Places'][j]['PlaceId']\n",
    "            iatacode = price_dataframe.loc[i, 'Places'][j]['IataCode']\n",
    "            name = price_dataframe.loc[i, 'Places'][j]['Name']\n",
    "            cityname = price_dataframe.loc[i, 'Places'][j]['CityName']\n",
    "            countryname = price_dataframe.loc[i, 'Places'][j]['CountryName']\n",
    "            \n",
    "            individual_places_dict = {'PlaceId':placeid,\n",
    "                                    'IataCode':iatacode,\n",
    "                                    'Name':name,\n",
    "                                    'CityName':cityname,\n",
    "                                    'CountryName':countryname}\n",
    "\n",
    "            individual_places_df = pd.DataFrame(individual_places_dict, columns = individual_places_dict.keys(), index = [j])\n",
    "            places = pd.concat([places, individual_places_df])\n",
    "\n",
    "\n",
    "    ## Makes the Carriers DataFrame\n",
    "    for i in range(len(price_dataframe)):\n",
    "        for j in range(len(price_dataframe.loc[i, 'Carriers'])):\n",
    "            carrierid = price_dataframe.loc[i, 'Carriers'][j]['CarrierId']\n",
    "            name = price_dataframe.loc[i, 'Carriers'][j]['Name']\n",
    "\n",
    "            individual_carriers_dict = {'CarrierId': carrierid,\n",
    "                                        'Name': name}\n",
    "            \n",
    "            individual_carriers_df = pd.DataFrame(individual_carriers_dict, columns = individual_carriers_dict.keys(), index = [j])\n",
    "            carriers = pd.concat([carriers, individual_carriers_df])\n",
    "\n",
    "\n",
    "    ## Cleans the Quotes DataFrame\n",
    "    quotes.drop_duplicates(inplace = True)\n",
    "    quotes.reset_index(inplace = True)\n",
    "    quotes.drop(columns = 'index', inplace = True)\n",
    "    quotes.rename(columns = {'CarrierIds':'CarrierId'}, inplace = True)\n",
    "\n",
    "    ## Cleans the Places Dataframe\n",
    "    places.drop_duplicates(inplace = True)\n",
    "    places.reset_index(inplace = True)\n",
    "    places.drop(columns = 'index', inplace = True)\n",
    "    places['OriginId'] = places['PlaceId']\n",
    "    places['DestinationId'] = places['PlaceId']\n",
    "    places.drop(columns = 'PlaceId', inplace = True)\n",
    "\n",
    "    ## Cleans the Carriers Dataframe\n",
    "    carriers.drop_duplicates(inplace = True)\n",
    "    carriers.reset_index(inplace = True)\n",
    "    carriers.drop(columns = 'index', inplace = True)\n",
    "    carriers.rename(columns = {'Name':'CarrierName'}, inplace = True)\n",
    "\n",
    "\n",
    "    #Merging of three dataframes\n",
    "    quotes = pd.merge(quotes, right = places, how = 'inner', on = 'OriginId') #Merges places on \n",
    "    quotes.drop(columns = 'DestinationId_y', inplace = True)\n",
    "    quotes.rename(columns = {'DestinationId_x':'DestinationId', 'IataCode':'OriginIataCode','Name':'OriginName', 'CityName':'OriginCityName', 'CountryName':'OriginCountryName'}, inplace = True)\n",
    "    \n",
    "    quotes = pd.merge(quotes, right = places, how = 'inner', on = 'DestinationId')\n",
    "    quotes.drop(columns = 'OriginId_y', inplace = True)\n",
    "    quotes.rename(columns = {'OriginId_x':'OriginId', 'IataCode':'DestinationIataCode','Name':'DestinationName', 'CityName':'DestinationCityName', 'CountryName':'DestinationCountryName'}, inplace = True)\n",
    "\n",
    "    quotes = pd.merge(quotes, right = carriers, how = 'inner', on = 'CarrierId')\n",
    "   \n",
    "\n",
    "    return quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2021 = create_targetframe(monthly_pricing_2021) #creates the 2021 quotes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QuoteId</th>\n      <th>MinPrice</th>\n      <th>Direct</th>\n      <th>CarrierId</th>\n      <th>OriginId</th>\n      <th>DestinationId</th>\n      <th>DepartureDate</th>\n      <th>OriginIataCode</th>\n      <th>OriginName</th>\n      <th>OriginCityName</th>\n      <th>OriginCountryName</th>\n      <th>DestinationIataCode</th>\n      <th>DestinationName</th>\n      <th>DestinationCityName</th>\n      <th>DestinationCountryName</th>\n      <th>CarrierName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>176.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96268</td>\n      <td>73076</td>\n      <td>2021-05-04T00:00:00</td>\n      <td>YUL</td>\n      <td>Montreal Pierre Elliott Trudeau</td>\n      <td>Montreal</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>176.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96268</td>\n      <td>73076</td>\n      <td>2021-05-15T00:00:00</td>\n      <td>YUL</td>\n      <td>Montreal Pierre Elliott Trudeau</td>\n      <td>Montreal</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>125.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96474</td>\n      <td>73076</td>\n      <td>2021-04-05T00:00:00</td>\n      <td>YYZ</td>\n      <td>Toronto Pearson International</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>125.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96474</td>\n      <td>73076</td>\n      <td>2021-04-26T00:00:00</td>\n      <td>YYZ</td>\n      <td>Toronto Pearson International</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>125.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96474</td>\n      <td>73076</td>\n      <td>2021-05-03T00:00:00</td>\n      <td>YYZ</td>\n      <td>Toronto Pearson International</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>3</td>\n      <td>132.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>40924</td>\n      <td>68033</td>\n      <td>2021-01-03T00:00:00</td>\n      <td>ATL</td>\n      <td>Atlanta Hartsfield-Jackson</td>\n      <td>Atlanta</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>4</td>\n      <td>87.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>40924</td>\n      <td>68033</td>\n      <td>2021-01-04T00:00:00</td>\n      <td>ATL</td>\n      <td>Atlanta Hartsfield-Jackson</td>\n      <td>Atlanta</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>4</td>\n      <td>112.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>42995</td>\n      <td>68033</td>\n      <td>2021-01-14T00:00:00</td>\n      <td>BOS</td>\n      <td>Boston Logan International</td>\n      <td>Boston</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>1</td>\n      <td>1509.0</td>\n      <td>True</td>\n      <td>1490</td>\n      <td>42553</td>\n      <td>74728</td>\n      <td>2021-01-07T00:00:00</td>\n      <td>BFI</td>\n      <td>Seattle Boeing Fld</td>\n      <td>Seattle</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Linear Air</td>\n    </tr>\n    <tr>\n      <th>1266</th>\n      <td>2</td>\n      <td>1509.0</td>\n      <td>True</td>\n      <td>1490</td>\n      <td>42553</td>\n      <td>74728</td>\n      <td>2021-01-08T00:00:00</td>\n      <td>BFI</td>\n      <td>Seattle Boeing Fld</td>\n      <td>Seattle</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Linear Air</td>\n    </tr>\n  </tbody>\n</table>\n<p>1267 rows  16 columns</p>\n</div>",
      "text/plain": "     QuoteId  MinPrice Direct CarrierId OriginId DestinationId  \\\n0          1     176.0   True       835    96268         73076   \n1          2     176.0   True       835    96268         73076   \n2          1     125.0   True       835    96474         73076   \n3          2     125.0   True       835    96474         73076   \n4          1     125.0   True       835    96474         73076   \n...      ...       ...    ...       ...      ...           ...   \n1262       3     132.0   True      1467    40924         68033   \n1263       4      87.0   True      1467    40924         68033   \n1264       4     112.0   True      1467    42995         68033   \n1265       1    1509.0   True      1490    42553         74728   \n1266       2    1509.0   True      1490    42553         74728   \n\n            DepartureDate OriginIataCode                       OriginName  \\\n0     2021-05-04T00:00:00            YUL  Montreal Pierre Elliott Trudeau   \n1     2021-05-15T00:00:00            YUL  Montreal Pierre Elliott Trudeau   \n2     2021-04-05T00:00:00            YYZ    Toronto Pearson International   \n3     2021-04-26T00:00:00            YYZ    Toronto Pearson International   \n4     2021-05-03T00:00:00            YYZ    Toronto Pearson International   \n...                   ...            ...                              ...   \n1262  2021-01-03T00:00:00            ATL       Atlanta Hartsfield-Jackson   \n1263  2021-01-04T00:00:00            ATL       Atlanta Hartsfield-Jackson   \n1264  2021-01-14T00:00:00            BOS       Boston Logan International   \n1265  2021-01-07T00:00:00            BFI               Seattle Boeing Fld   \n1266  2021-01-08T00:00:00            BFI               Seattle Boeing Fld   \n\n     OriginCityName OriginCountryName DestinationIataCode  \\\n0          Montreal            Canada                 ORD   \n1          Montreal            Canada                 ORD   \n2           Toronto            Canada                 ORD   \n3           Toronto            Canada                 ORD   \n4           Toronto            Canada                 ORD   \n...             ...               ...                 ...   \n1262        Atlanta     United States                 MIA   \n1263        Atlanta     United States                 MIA   \n1264         Boston     United States                 MIA   \n1265        Seattle     United States                 PDX   \n1266        Seattle     United States                 PDX   \n\n                   DestinationName DestinationCityName DestinationCountryName  \\\n0     Chicago O'Hare International             Chicago          United States   \n1     Chicago O'Hare International             Chicago          United States   \n2     Chicago O'Hare International             Chicago          United States   \n3     Chicago O'Hare International             Chicago          United States   \n4     Chicago O'Hare International             Chicago          United States   \n...                            ...                 ...                    ...   \n1262           Miami International               Miami          United States   \n1263           Miami International               Miami          United States   \n1264           Miami International               Miami          United States   \n1265                      Portland            Portland          United States   \n1266                      Portland            Portland          United States   \n\n          CarrierName  \n0          Air Canada  \n1          Air Canada  \n2          Air Canada  \n3          Air Canada  \n4          Air Canada  \n...               ...  \n1262  Spirit Airlines  \n1263  Spirit Airlines  \n1264  Spirit Airlines  \n1265       Linear Air  \n1266       Linear Air  \n\n[1267 rows x 16 columns]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking the 2020 Monthly Pricing Dataframe and Null Analysis\n",
    "\n",
    "The 2020 monthyl pricing dataframe follows the same formatting as the 2021 monthly pricing dataframe -- which means it will require the same sort of cleaning. From what we learned from the above dataframe cleaning, we will apply the same logic to ultimately yield a `quotes_2020` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0                                             Quotes  \\\n0           0                                                 []   \n1           1  [{'QuoteId': 1, 'MinPrice': 327.0, 'Direct': F...   \n2           2  [{'QuoteId': 1, 'MinPrice': 353.0, 'Direct': F...   \n3           3                                                 []   \n4           4                                                 []   \n\n                                              Places  \\\n0                                                 []   \n1  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n2  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n3                                                 []   \n4                                                 []   \n\n                                   Carriers  \\\n0                                        []   \n1  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n2  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n3                                        []   \n4                                        []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n415         415  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n416         416  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n417         417  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n418         418  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n419         419  [{'QuoteId': 1, 'MinPrice': 63.0, 'Direct': Tr...   \n\n                                                Places  \\\n415  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n416  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n417  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n418  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n419  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n415  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n416  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n417  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n418  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n419  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n\n                                            Currencies ValidationErrors  \n415  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n416  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n417  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n418  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n419  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 420 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 420 entries, 0 to 419\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        420 non-null    int64 \n 1   Quotes            406 non-null    object\n 2   Places            406 non-null    object\n 3   Carriers          406 non-null    object\n 4   Currencies        406 non-null    object\n 5   ValidationErrors  14 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 19.8+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(june2020_to_december2020_monthlyprice) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 5823 rows and 6 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_unnamed(june2020_to_december2020_monthlyprice) #drops the unnamed column in the 2020 dataframne\n",
    "null_analysis(june2020_to_december2020_monthlyprice) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "june2020_to_december2020_monthlyprice.dropna(subset = ['Quotes'], inplace = True) #drops the nulls in the dataframe pivoting off the quotes column\n",
    "june2020_to_december2020_monthlyprice.drop(columns = 'ValidationErrors', inplace = True) #drops the validation errors column\n",
    "null_analysis(june2020_to_december2020_monthlyprice) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "june2020_to_december2020_monthlyprice['Quotes'] = june2020_to_december2020_monthlyprice['Quotes'].replace(\"[]\", np.nan) #replaces the \"empty lists\" with NaNs\n",
    "null_analysis(june2020_to_december2020_monthlyprice) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "june2020_to_december2020_monthlyprice.dropna(subset = ['Quotes'], inplace = True) #drops the recognized nulls in the Quotes column to have an effect across the entire dataframe\n",
    "as_lit_for_json(june2020_to_december2020_monthlyprice) #converts the dataframe's strings\n",
    "june2020_to_december2020_monthlyprice.drop(columns = 'Currencies', inplace = True)\n",
    "june2020_to_december2020_monthlyprice.reset_index(inplace = True)\n",
    "june2020_to_december2020_monthlyprice.drop(columns = 'index', inplace = True)\n",
    "quotes_2020 = create_targetframe(june2020_to_december2020_monthlyprice) #creates the 2020 quotes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.03 Other Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.04 Creating the Model Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Future Work\n",
    "\n",
    "For the future, consider incorporating weather data, randomized passenger weight data, incorporate the dynamic changes in fuel/mass ratio throughout a flight, incorporate some demographical passenger data, more routes, the ability for the problem to become a UI tool rather than just a study."
   ]
  }
 ]
}