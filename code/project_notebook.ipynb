{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdsitestconda48790fb83d3f473c989768c98a666b4b",
   "display_name": "Python 3.7.6 64-bit ('DSI_test': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Airline Prices\n",
    "By: Chirstopher Kuzemka : [Github](https://git.generalassemb.ly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Aviation is one of the largest industries dominating our global market today. Commercial aviation has made it possible for people to connect with each other in ways that may have been unimaginable over a century ago. However, a lot of thought must be put into the FAA standards and routes that modern planes must make today to make such connections possible.\n",
    "\n",
    "Consider the case example where a startup airliner, known as \"Kruze\", wants to establish itself as a top competitor against existing airliners today. A part of this startup process focuses on understanding the costs that will come into play when managing flights. Our job as data scientists today is to help Kruze determine the minimum threshold cost the airliner must charge their passengers on a ticket class basis in order to break even with a profit. To do this, we are going to use existing flight routes (velocity and altitude data), existing data on jet fuel pricing, and existing flight ticket prices (as a prediction) to help us create a supervised learning model. \n",
    "\n",
    "To start, we will approach the project with the intention of expressing a minimum proof of concept. With such introduction, we will make some limitations to our study and decrease the potential for scope increase by:\n",
    "\n",
    "- conducting an idealized thermal jet propulsion cycle for feature engineering purposes (focusing on an open Brayton cycle in particular)\n",
    "- analyzing flight route data across the U.S. domestically; choosing up to 3 routes of varying sizes and suggesting their reverse flight paths as data inputs as well. \n",
    "    - **Houston, TX** to **Los Angeles, CA** (IAH - LAX)\n",
    "    - **New York City, NY** to **Miami, FL** (JFK - MIA)\n",
    "    - **Portland, WA** to **Chicago, IL** (PDX - ORD)\n",
    "- assuming air to be treated as an ideal gas\n",
    "- assuming operating engine conditions to be steady state\n",
    "- assuming kinetic energy and potential energy to be negligible in our system, except at inlet and exit conditioins of jet engine itself\n",
    "- assuming atmospheric temperature, pressure, and air density to be an averaged value between 0 and 15,000 meters altitude\n",
    "- assuming data incorporating head or tail wind effects to be negligible\n",
    "- assuming passenger weight to be negligible\n",
    "- assuming external costs from the study (including food/maintenance/crew salary) to be negligible\n",
    "- using price data from future flights as opposed to previous flights as previous flight pricing is not readily available\n",
    "\n",
    "\n",
    "All current assumptions labeled are set to allow us to achieve (or attempt to achieve) our goal within a certain time frame, as Kruze is requiring an answer from us quickly! With this in mind, we will consider discussing how such assumptions can contribute to any error throughout our study, as well as remind ourselves that integrating negated features for future work may actually be very beneficial to us in achieveing a stronger prediction. Conducting an idealized thermal engine analysis will help us understand the average power output of a given plane's engines throughout different phases of its flight. Routes chosen throughout a variety of times and seasons will also help us determine how such elements play a role in pricing. Finally, some plane specifications (including aircraft type, number of seats it supports, as well as type/number of engines) will allow us to consider any extra technical factors for ticket pricing. \n",
    "\n",
    "As we are working with what is considerred to be a continuous variable, we will analyze common price trends utilizing a supervised regression model, such as Linear Regression, Logistic Regression, SVR, AdaBoosting Regression, Gradient Boosting Regression, KNNRegression, and Naive Bayes Regression. We will ultimately be using the Mean Absolute Error against our predictions to help us gauge how well our selected model predicts the price and discuss what issues may be observed from the limitations of this study.\n",
    "\n",
    "\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "## Table of Contents\n",
    "[1.00 Data Loading](#1.00-Data-Loading)\n",
    "\n",
    "[2.00 Superficial Analysis and History](#2.00-Superficial-Analysis-and-History)\n",
    "\n",
    "- [2.01 Quick Check](#2.01-Quick-Check)\n",
    "\n",
    "- [2.02 Data Documentation Exploration](#2.02-Data-Documentation-Exploration)\n",
    "\n",
    "[3.00 Data Cleaning](#3.00-Data-Cleaning)  \n",
    "\n",
    "[4.00 Exploratory Data Analysis and Visualization](#4.00-Exploratory-Data-Analysis-and-Visualization)\n",
    "\n",
    "[5.00 Machine Learning Modeling and Visulalization](#5.00-Machine-Learning-Modeling-and-Visulalization)\n",
    "\n",
    "- [3.01 Model Preparation](#3.01-Model-Preparation)\n",
    "\n",
    "- [3.02 Modeling](#3.02-Modeling)\n",
    "\n",
    "- [3.03 Model Selection](#3.03-Model-Selection)\n",
    "\n",
    "- [3.04 Model Evaluation](#3.04-Model-Evaluation)\n",
    "\n",
    "[6.00 Conclusions](#6.00-Conclusions)\n",
    "\n",
    "[7.00 Sources and References](#7.00-Sources-and-References)\n",
    "\n",
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.00 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "\nBad key \"text.kerning_factor\" on line 4 in\n/Users/ChristopherKuzemka/opt/anaconda3/envs/DSI_test/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\nYou probably need to get an updated matplotlibrc file from\nhttps://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\nor from the matplotlib source distribution\n"
    }
   ],
   "source": [
    "import pandas as pd #imports the pandas package\n",
    "import numpy as np #imports the numpy package\n",
    "import matplotlib.pyplot as plt #imports the matplotlib plotting package\n",
    "import seaborn as sns #imports the seaborn package\n",
    "\n",
    "import json #imports the json package\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.01 Flight Tracking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_flights = pd.read_csv('../data/current_flights.csv') #reads the current_flights csv\n",
    "flight_combinations = pd.read_csv('../data/flight_combinations.csv') #reads the flight_combinations csv\n",
    "flight_schedules = pd.read_csv('../data/flight_schedules.csv') #reads the flight_schedules csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.02 Pricing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021 = pd.read_csv('../data/2021_monthly_pricing2.csv') #reads the 2021_monthly_pricing csv\n",
    "june2020_to_december2020_monthlyprice = pd.read_csv('../data/june2020_to_december2020_monthlyprice.csv') #reads the 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.03 Additional Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_checkpoint_travel = pd.read_excel('../data/tsa_checkpoint_travel.xlsx', sheet_name = 'Sheet1', index_col = None, usecols = 'A:C') #reads the tsa_checkpoint_travel xlsx\n",
    "tsa_confirmed_cases = pd.read_excel('../data/tsa_confirmed_cases.xlsx', sheet_name = 'Sheet1', index_col = None, usecols=  'A:E') #reads the tsa_confirmed_cases xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.00 Data Data Cleaning and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.01 Quick Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_check(dataframe):\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The head of your input dataframe is dataframe is:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.head()) #checks the head of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The tail of your input dataframe is:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.tail()) #checks the tail of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The shape of the dataframe is {dataframe.shape[0]} rows and {dataframe.shape[1]} columns.\") #checks the shape of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows whether there exist nulls in our dataframe or not:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.isnull().any()) #checks the null status of the current_flights dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows the useful information to be aware of when exploring this input dataframe:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.info()) #checks the null status of the current_flights dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function is created to conveniently conduct a quick check on the dataframe for the reader/user. Through it, we will able to see the __head__, __tail__, __shape__, __null presence__, and __important dataframe information__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Flights Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0                      faFlightID   ident prefix  type  suffix  \\\n0           0       DAL333-1590465975-fa-0008  DAL333    NaN  A321     NaN   \n1           1  KLM601-1590468354-airline-0005  KLM601    NaN  B77W     NaN   \n2           2       VIR607-1590664542-ed-0002  VIR607    NaN  B789     NaN   \n3           3       DAL702-1590465982-fa-0006  DAL702    NaN  A321     NaN   \n4           4  ACA572-1590468353-airline-0278  ACA572    NaN  A319     NaN   \n\n  origin destination  timeout   timestamp  ...  lowLatitude  highLongitude  \\\n0   KATL        KLAX        0  1590716390  ...     32.94676      -84.44664   \n1   EHAM        KLAX        0  1590711509  ...     33.95142        4.71741   \n2   EGLL        KLAX        0  1590711368  ...     33.95091       -0.39345   \n3   KATL        KLAX        0  1590709847  ...     33.64682      -84.44602   \n4   CYVR        KLAX        0  1590706589  ...     33.95183     -118.17553   \n\n   highLatitude  groundspeed  altitude  heading  altitudeStatus  updateType  \\\n0      33.70005          448       300      264             NaN           A   \n1      66.06976          130         1      263             NaN           A   \n2      66.09780          101         1      263             NaN           A   \n3      35.52932          117         1      263             NaN           A   \n4      49.18984          109         1      263             NaN           A   \n\n   altitudeChange                                          waypoints  \n0               D  33.64 -84.43 33.68 -84.28 33.81 -84.28 33.81 -...  \n1               D  52.31 4.76 53.02 2.53 53.06 2.46 53.2 1.53 53....  \n2               D  51.48 -0.46 51.56 -0.59 51.62 -0.68 51.7 -0.79...  \n3               D  33.64 -84.43 33.68 -84.28 33.79 -85 33.81 -85....  \n4               D  49.19 -123.18 49.12 -123.26 49.12 -123.27 49.0...  \n\n[5 rows x 26 columns]\n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                       faFlightID    ident prefix  type  \\\n100         100  EDV4708-1590468354-airline-0112  EDV4708    NaN  CRJ9   \n101         101        ABW341-1590583043-eb-0002   ABW341    NaN  B744   \n102         102  DLH8176-1590641113-airline-0180  DLH8176    NaN  B772   \n103         103  CLX8626-1590641113-airline-0361  CLX8626    NaN  B744   \n104         104  DLH8172-1590641113-airline-0177  DLH8172    NaN  MD11   \n\n     suffix origin destination  timeout   timestamp  ...  lowLatitude  \\\n100     NaN   KAGS        KATL        0  1590664135  ...     33.19607   \n101     NaN   EBLG        KATL        0  1590631398  ...     33.53333   \n102     NaN   EDDF        KATL        0           0  ...    200.00000   \n103     NaN   ELLX        KATL        0           0  ...    200.00000   \n104     NaN   EDDF        KATL        0           0  ...    200.00000   \n\n     highLongitude  highLatitude  groundspeed  altitude  heading  \\\n100      -81.97964      33.63222          126        10       91   \n101        5.56940      54.10380          132         9       90   \n102     -200.00000    -200.00000            0         0        0   \n103     -200.00000    -200.00000            0         0        0   \n104     -200.00000    -200.00000            0         0        0   \n\n     altitudeStatus  updateType  altitudeChange  \\\n100             NaN           A               D   \n101                           A               D   \n102             NaN         NaN             NaN   \n103             NaN         NaN             NaN   \n104             NaN         NaN             NaN   \n\n                                             waypoints  \n100  33.37 -81.96 33.39 -82.03 33.39 -82.04 33.38 -...  \n101  50.64 5.44 50.69 5.24 50.73 5.08 50.78 4.89 50...  \n102                                                NaN  \n103                                                NaN  \n104                                                NaN  \n\n[5 rows x 26 columns]\n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 105 rows and 26 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0           False\nfaFlightID           False\nident                False\nprefix                True\ntype                  True\nsuffix                True\norigin               False\ndestination          False\ntimeout              False\ntimestamp            False\ndepartureTime        False\nfirstPositionTime    False\narrivalTime          False\nlongitude            False\nlatitude             False\nlowLongitude         False\nlowLatitude          False\nhighLongitude        False\nhighLatitude         False\ngroundspeed          False\naltitude             False\nheading              False\naltitudeStatus        True\nupdateType            True\naltitudeChange        True\nwaypoints             True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 105 entries, 0 to 104\nData columns (total 26 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Unnamed: 0         105 non-null    int64  \n 1   faFlightID         105 non-null    object \n 2   ident              105 non-null    object \n 3   prefix             1 non-null      object \n 4   type               103 non-null    object \n 5   suffix             0 non-null      float64\n 6   origin             105 non-null    object \n 7   destination        105 non-null    object \n 8   timeout            105 non-null    int64  \n 9   timestamp          105 non-null    int64  \n 10  departureTime      105 non-null    int64  \n 11  firstPositionTime  105 non-null    int64  \n 12  arrivalTime        105 non-null    int64  \n 13  longitude          105 non-null    float64\n 14  latitude           105 non-null    float64\n 15  lowLongitude       105 non-null    float64\n 16  lowLatitude        105 non-null    float64\n 17  highLongitude      105 non-null    float64\n 18  highLatitude       105 non-null    float64\n 19  groundspeed        105 non-null    int64  \n 20  altitude           105 non-null    int64  \n 21  heading            105 non-null    int64  \n 22  altitudeStatus     31 non-null     object \n 23  updateType         90 non-null     object \n 24  altitudeChange     90 non-null     object \n 25  waypoints          89 non-null     object \ndtypes: float64(7), int64(9), object(10)\nmemory usage: 21.5+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(current_flights) #performs a quick check on the current_flights dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 105 rows and 26 columns. Not all columns are revealed in the head and tail of the function. \n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- Most of the values in our dataframe are numerical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Combinations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0 origin destination  0\n0           0   CYHM        KJFK  1\n1           1   CYUL        KORD  1\n2           2   CYVR        KLAX  1\n3           3   CYYZ        KIAH  2\n4           4   CYYZ        KJFK  1\n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Unnamed: 0 origin destination  0\n55          55   KBUR        KPDX  1\n56          56   KBWI        KPDX  1\n57          57   KCVG        KPDX  1\n58          58   KCVO        KPDX  2\n59          59   KDEN        KPDX  3\n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 60 rows and 4 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0     False\norigin         False\ndestination    False\n0              False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 60 entries, 0 to 59\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   Unnamed: 0   60 non-null     int64 \n 1   origin       60 non-null     object\n 2   destination  60 non-null     object\n 3   0            60 non-null     int64 \ndtypes: int64(2), object(2)\nmemory usage: 2.0+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(flight_combinations) #performs a quick check on the flight combinations dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Takeaways form the above output:\n",
    "\n",
    "- There is an `Unnamed: 0` column which does not need to be included. \n",
    "\n",
    "- The dataframe is 60 rows and has 4 columns. \n",
    "\n",
    "- The column named `0` is the final column and shows the frequency of the flight combination shown in the dataframe. \n",
    "\n",
    "- There are no nulls. \n",
    "\n",
    "- All of the values are numerical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Schedules Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0    ident actual_ident  departuretime  arrival_time origin  \\\n0           0  UAL4282      ASQ4282     1588330800    1588340820   CYUL   \n1           1  ACA7591      AC27591     1588335000    1588343880   CYUL   \n2           2  UAL8371      AC27591     1588335000    1588343880   CYUL   \n3           3  UAL4245      ASQ4245     1588341060    1588351080   CYUL   \n4           4  UAL8481      AC27595     1588353300    1588362000   CYUL   \n\n  destination aircrafttype                                       meal_service  \\\n0        KORD         E75L    Business: Refreshments / Economy: Food for sale   \n1        KORD         E75L  Business: Breakfast / Economy: Breakfast, Food...   \n2        KORD         E75L       Business: Breakfast / Economy: Food for sale   \n3        KORD         E75L    Business: Refreshments / Economy: Food for sale   \n4        KORD         E75L            Business: Meal / Economy: Food for sale   \n\n   seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n0                  0                    12                 58  \n1                  0                    12                 64  \n2                  0                    12                 64  \n3                  0                    12                 58  \n4                  0                    12                 64  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n      Unnamed: 0    ident actual_ident  departuretime  arrival_time origin  \\\n5818        5818   UAL464          NaN     1590514200    1590523860   KDEN   \n5819        5819   SWA378          NaN     1590520500    1590529500   KDEN   \n5820        5820  DLH9070       UAL393     1590539460    1590549120   KDEN   \n5821        5821   UAL393          NaN     1590539460    1590549120   KDEN   \n5822        5822   SWA993          NaN     1590544800    1590554400   KDEN   \n\n     destination aircrafttype                                  meal_service  \\\n5818        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5819        KPDX         B738                              Economy: No meal   \n5820        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5821        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5822        KPDX         B738                              Economy: No meal   \n\n      seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n5818                  0                    12                114  \n5819                  0                     0                175  \n5820                  0                    12                114  \n5821                  0                    12                114  \n5822                  0                     0                175  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 5823 rows and 12 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0              False\nident                   False\nactual_ident             True\ndeparturetime           False\narrival_time            False\norigin                  False\ndestination             False\naircrafttype             True\nmeal_service             True\nseats_cabin_first       False\nseats_cabin_business    False\nseats_cabin_coach       False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5823 entries, 0 to 5822\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   Unnamed: 0            5823 non-null   int64 \n 1   ident                 5823 non-null   object\n 2   actual_ident          4639 non-null   object\n 3   departuretime         5823 non-null   int64 \n 4   arrival_time          5823 non-null   int64 \n 5   origin                5823 non-null   object\n 6   destination           5823 non-null   object\n 7   aircrafttype          5373 non-null   object\n 8   meal_service          5429 non-null   object\n 9   seats_cabin_first     5823 non-null   int64 \n 10  seats_cabin_business  5823 non-null   int64 \n 11  seats_cabin_coach     5823 non-null   int64 \ndtypes: int64(6), object(6)\nmemory usage: 546.0+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(flight_schedules) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 5823 rows and 12 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have an even split of numerical and string values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Pricing 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0 Quotes Places Carriers  \\\n0           0     []     []       []   \n1           1     []     []       []   \n2           2     []     []       []   \n3           3     []     []       []   \n4           4     []     []       []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n715         715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716         716                                                 []   \n717         717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718         718                                                 []   \n719         719                                                 []   \n\n                                                Places  \\\n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies ValidationErrors  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 720 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 720 entries, 0 to 719\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        720 non-null    int64 \n 1   Quotes            696 non-null    object\n 2   Places            696 non-null    object\n 3   Carriers          696 non-null    object\n 4   Currencies        696 non-null    object\n 5   ValidationErrors  24 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 33.9+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(monthly_pricing_2021) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways from the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 720 rows and 7 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### June 2020 To December 2020 Monthly Prices Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0                                             Quotes  \\\n0           0                                                 []   \n1           1  [{'QuoteId': 1, 'MinPrice': 327.0, 'Direct': F...   \n2           2  [{'QuoteId': 1, 'MinPrice': 353.0, 'Direct': F...   \n3           3                                                 []   \n4           4                                                 []   \n\n                                              Places  \\\n0                                                 []   \n1  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n2  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n3                                                 []   \n4                                                 []   \n\n                                   Carriers  \\\n0                                        []   \n1  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n2  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n3                                        []   \n4                                        []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n415         415  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n416         416  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n417         417  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n418         418  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n419         419  [{'QuoteId': 1, 'MinPrice': 63.0, 'Direct': Tr...   \n\n                                                Places  \\\n415  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n416  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n417  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n418  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n419  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n415  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n416  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n417  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n418  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n419  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n\n                                            Currencies ValidationErrors  \n415  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n416  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n417  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n418  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n419  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 420 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 420 entries, 0 to 419\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        420 non-null    int64 \n 1   Quotes            406 non-null    object\n 2   Places            406 non-null    object\n 3   Carriers          406 non-null    object\n 4   Currencies        406 non-null    object\n 5   ValidationErrors  14 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 19.8+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(june2020_to_december2020_monthlyprice) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 5823 rows and 6 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSA Checkpoint Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n        Date  Total Traveler Throughput  Total Traveler Throughput.1\n0        NaT                        NaN  (1 Year Ago - Same Weekday)\n1 2020-05-26                   264843.0                      2453649\n2 2020-05-25                   340769.0                      2512237\n3 2020-05-24                   267451.0                      2070716\n4 2020-05-23                   253190.0                      2124825\n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n         Date  Total Traveler Throughput Total Traveler Throughput.1\n83 2020-03-05                  2130015.0                     2402692\n84 2020-03-04                  1877401.0                     2143619\n85 2020-03-03                  1736393.0                     1979558\n86 2020-03-02                  2089641.0                     2257920\n87 2020-03-01                  2280522.0                     2301439\n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 88 rows and 3 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nDate                            True\nTotal Traveler Throughput       True\nTotal Traveler Throughput.1    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 88 entries, 0 to 87\nData columns (total 3 columns):\n #   Column                       Non-Null Count  Dtype         \n---  ------                       --------------  -----         \n 0   Date                         87 non-null     datetime64[ns]\n 1   Total Traveler Throughput    87 non-null     float64       \n 2   Total Traveler Throughput.1  88 non-null     object        \ndtypes: datetime64[ns](1), float64(1), object(1)\nmemory usage: 2.2+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(tsa_checkpoint_travel) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- There is a `Date` column not currently set as the index of the dataframe. We will consider making the `Date` column the index. \n",
    "\n",
    "- The first row seems to contain header information. We will append the appropriate values into the header. \n",
    "\n",
    "- Our dataframe is 88 rows and 3 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have an even split of string, float, and datetime values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSA Confirmed Cases Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                          Airport  Total Confirmed Cases  \\\n0               ACY - Atlantic City International                      1   \n1                        AIA - Alliance Municipal                      1   \n2                      ALW - Walla Walla Regional                      1   \n3       AMA - Rick Husband Amarillo International                      1   \n4  ATL - Hartsfield-Jackson Atlanta International                     17   \n\n   TSA Screening Officers  Non-Screening Employees  \\\n0                     1.0                      NaN   \n1                     1.0                      NaN   \n2                     1.0                      NaN   \n3                     1.0                      NaN   \n4                    16.0                      1.0   \n\n  Last work date of most recent screening officer confirmed case  \n0                                         2020-05-16              \n1                                         2020-05-19              \n2                                         2020-03-24              \n3                                         2020-05-02              \n4                                         2020-03-18              \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                  Airport  Total Confirmed Cases  \\\n73  STL - St. Louis Lambert International                      1   \n74                     STT - Cyril E King                      1   \n75             TLH - Tallahassee Regional                      1   \n76                   TOL - Toledo Express                      2   \n77              TPA - Tampa International                      2   \n\n    TSA Screening Officers  Non-Screening Employees  \\\n73                     1.0                      NaN   \n74                     1.0                      NaN   \n75                     1.0                      NaN   \n76                     2.0                      NaN   \n77                     1.0                      1.0   \n\n   Last work date of most recent screening officer confirmed case  \n73                                         2020-04-27              \n74                                         2020-03-13              \n75                                         2020-05-04              \n76                                         2020-04-06              \n77                                         2020-04-08              \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 78 rows and 5 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nAirport                                                           False\nTotal Confirmed Cases                                             False\nTSA Screening Officers                                             True\nNon-Screening Employees                                            True\nLast work date of most recent screening officer confirmed case     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 78 entries, 0 to 77\nData columns (total 5 columns):\n #   Column                                                          Non-Null Count  Dtype         \n---  ------                                                          --------------  -----         \n 0   Airport                                                         78 non-null     object        \n 1   Total Confirmed Cases                                           78 non-null     int64         \n 2   TSA Screening Officers                                          76 non-null     float64       \n 3   Non-Screening Employees                                         22 non-null     float64       \n 4   Last work date of most recent screening officer confirmed case  76 non-null     datetime64[ns]\ndtypes: datetime64[ns](1), float64(2), int64(1), object(1)\nmemory usage: 3.2+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(tsa_confirmed_cases) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The data columns are separated above with a `\\`.\n",
    "\n",
    "- Our dataframe is 78 rows and 5 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have string, float, and datetime values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.02 Data Documentation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the \"Flight Data\"?\n",
    "\n",
    "The \"Flight Data\" is referring to the the dataframes showcasing the current flights (`current_flights`), flight combinations (`flight_combinations`), and flight schedules(`flight_schedules`). They each preside in the order which they were constructed, where the `current_flights` dataframe was collected first, then the `flight_combinations`, then the `flight_schedules`. All of the flight data collected stemmed from the root dataframe for this study: `current_flights`. Below are the data dictionaries for each dataframe after their cleaning process showcased in [3.00 Data Cleaning](#3.00-Data-Cleaning). The data dictionaries are to help us understand what each dataframe's value represents as the airline language can be non-intuitive to understand. Some of the values are also representing identifiers the API utilized to gather the data. The main dataframe which we will be using for our model will be the `flight_schedules` dataframe. The other dataframes will showcase various aspects of the `flight_schedules` dataframe to help Kruze understand the analysis presented here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How was the Flight Data Gathered?\n",
    "\n",
    "__*The below information is also stated in the `flight_aware_data_scrape.ipynb` file in this study. Please refer to the `flight_aware_data_scrape.ipynb` file to see the detailed Python scripts written to perform this data collection*__\n",
    "\n",
    "The most obvious candidate that came to mind for collecting data was collecting through [FlightAware.com](https://flightaware.com). It is the world's largest flight tracking data platform, which actively collects data directly from various air traffic control systems in many countries, including ground stations and satellites. Its powerful HyperFeed engine works with FlightAware's artificial intelligence network to gather data in real time. It serves as a reliable web-based source for data and provides a poweful API known as \"FlightXML\" to allow customers to gather useufl and comprehensive information on flights flown in history. Some notable companies rely on FlightAware for their data, such as *United, tripadvisor, Hawaiian Airlines, and more*. Many other APIs, which claim to collect flight data, will more than likely go through the FlightAware API as the root API.  \n",
    "\n",
    "With the above introduction, the next step was to gain access to the \"FlightXML\" API. A basic license of this API is free for users, in that there is no monthly subscription charge. However, all users of this API will be charged pennies for query searches - including basic license and more advanced license users. Furthermore, basic licensed users are not allowed to use tthe FlightXML API for commercial products.\n",
    "\n",
    "The API provided with the basic license is the \"FlightXML2\" API (\"FlightXML3\" does exist, but is believed to be exclusive for more advanced license users). The documentation for using the FlightXML2 API is found [here](https://flightaware.com/commercial/flightxml/explorer/#op_AirlineFlightInfo). To integrate the API's capabilities with our Python scripts, we also needed to integrate a package meant to work with SOAP/suds objects. The [suds](https://docs.inductiveautomation.com/display/DOC79/SUDS+-+Library+Overview) package was used to help us correctly use the API and gather different sets of data.  \n",
    "\n",
    "FlightXML2 is an excellent API for gathering a lot of data on flights in general. Their provided query search functionalities do not have a time limit, but do have a result limit set per search. A typical query search will include flight related data of up to 15 results. For example, searching for what current flights are arriving at John F. Kennedy Airport within a given timeframe and search will only return the latest 15 flights. There is offset functionality which allows a user to offset the 15 result search by any given integer and the user is also allowed to expand the maximum result search query (with the consequence of increasing costs). For this study, the maximum was not increased and offset functionaily was only implemented for some of the searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Biases Play a Role in the Data? What Compromises were Made?\n",
    "\n",
    "Let's provide some background context and conduct an experiment. According to [Flights.com](https://www.flights.com/flights/new-york-jfk-to-miami-mia/), \"With 3 different airlines operating flights between New York and Miami, there are, on average, 2,197 flights per month. This equates to about 523 flights per week, and 75 flights per day from JFK to MIA.\" If we were limited to this two week period to start with, we should be seeing enough flights only between two such popular locations in the U.S. for our study. However, when actually searching through FlightXML2, it was found that only 14 total flights were made in this two week time span. Such patterns of limited flights were observed across other airports. These kinds of trends existed even across a three month span. But why is this so?\n",
    "\n",
    "The timing of this study plays a trendous role in what outcomes we make from this. These searches were conducted towards the end of May of 2020 (Between May22nd and May29th). The furthest back we would've been able to search would've been towards the end of February/beginning of March in 2020. Coincidentally, this is the same point in time where global air travel restrictions are placed and volume of travel begins to drop, dramatically. By mid-March, [many major airports begin to close down due to the Covid-19 pandemic](https://www.businessinsider.com/coronavirus-airports-and-faa-centers-temporarily-closed-for-cleaning-2020-3#chicagos-midway-international-airport-1).\n",
    "\n",
    "With such limitations, a plan was conducted on how to gather much flight data. Instead of methodically picking popular routes where air traffic \"may\" exist between our target airports and other supposed popular airports, we decided to conduct a more random and and wider search for flight data. The goal was to get as much data as possible through the pandemic. \n",
    "\n",
    "- The first step made was to search active flights in the sky for each focused airport. On a given night (May 27th), 15 different flights were identified to arrive at any given airport. Of the seven destination airports, a total of 60 routes were collected. \n",
    "\n",
    "- The next step was to search each specific flight's schedule throughout the single month of May 2020. Even though we had the capability to search as far back as three months, we felt that utilizing the search on months where air traffic was extremely low (where some of our target airports were closed completely during the peak of the pandemic) would be a waste of money -- reminding ourselves that each query search costs a certain amount of pennies. Within this month timespan, query searches regarding a specific route was conducted on an eight hour time requency. Our search ran for approximately one hour before returning three dataframes: flight combinations, those current flights in the sky, and the flight schedules for that month. From 60 combinations of flights, we were able to obtain, approximately 5,800 data points of each flights history in that month. \n",
    "\n",
    "5,800 individual flights is extremely low when analyzing across seven different destination airports and utilizing 60 different flight combinations. Many of the query searches returned empty, possibly due to some flight cancellations. While this small set of data my not be ideal for the intended purpose of our study, it is enough to showcase a minimum proof of concept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Price Data?\n",
    "\n",
    "The \"Price Data\" is referring to the dataframes showcasing the quotes collected in 2020 (`june2020_to_december2020_monthylprice`) and the quotes collected in 2021 (`monthly_pricing_20201`). The pricing data hosts our target `MinPrice` column as well as other features which will be incorporated into our final dataframe for mondeling purposes. Each pricing dataframe are separate entities from one another and utilized flight combinations gathered from the FlightXML2 API. The IATA codes in particular were utilized to browse quotes across months in each year to help us gather more pricing data throughout the year for seasonality referencing. A data dictionary for the cleaned pricing dataframe (cleaned in [3.00 Data Cleaning](#3.00-Data-Cleaning)) consisting of both pricing dataframes is shown below. The ultimate pricing dataframe is known as `quotes`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How was the Price Data Gathered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Biases Play a Role in the Data? What Compromises were Made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the Other Relevant Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How was the Other Relevant Data Gathered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Biases Play a Role in the Data? What Compromises were Made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.00 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.01 Flight Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Analyzing the Flight Schedules Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0    ident actual_ident  departuretime  arrival_time origin  \\\n0           0  UAL4282      ASQ4282     1588330800    1588340820   CYUL   \n1           1  ACA7591      AC27591     1588335000    1588343880   CYUL   \n2           2  UAL8371      AC27591     1588335000    1588343880   CYUL   \n3           3  UAL4245      ASQ4245     1588341060    1588351080   CYUL   \n4           4  UAL8481      AC27595     1588353300    1588362000   CYUL   \n\n  destination aircrafttype                                       meal_service  \\\n0        KORD         E75L    Business: Refreshments / Economy: Food for sale   \n1        KORD         E75L  Business: Breakfast / Economy: Breakfast, Food...   \n2        KORD         E75L       Business: Breakfast / Economy: Food for sale   \n3        KORD         E75L    Business: Refreshments / Economy: Food for sale   \n4        KORD         E75L            Business: Meal / Economy: Food for sale   \n\n   seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n0                  0                    12                 58  \n1                  0                    12                 64  \n2                  0                    12                 64  \n3                  0                    12                 58  \n4                  0                    12                 64  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n      Unnamed: 0    ident actual_ident  departuretime  arrival_time origin  \\\n5818        5818   UAL464          NaN     1590514200    1590523860   KDEN   \n5819        5819   SWA378          NaN     1590520500    1590529500   KDEN   \n5820        5820  DLH9070       UAL393     1590539460    1590549120   KDEN   \n5821        5821   UAL393          NaN     1590539460    1590549120   KDEN   \n5822        5822   SWA993          NaN     1590544800    1590554400   KDEN   \n\n     destination aircrafttype                                  meal_service  \\\n5818        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5819        KPDX         B738                              Economy: No meal   \n5820        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5821        KPDX         A319  Business: Snack or brunch / Economy: No meal   \n5822        KPDX         B738                              Economy: No meal   \n\n      seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n5818                  0                    12                114  \n5819                  0                     0                175  \n5820                  0                    12                114  \n5821                  0                    12                114  \n5822                  0                     0                175  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 5823 rows and 12 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0              False\nident                   False\nactual_ident             True\ndeparturetime           False\narrival_time            False\norigin                  False\ndestination             False\naircrafttype             True\nmeal_service             True\nseats_cabin_first       False\nseats_cabin_business    False\nseats_cabin_coach       False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5823 entries, 0 to 5822\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   Unnamed: 0            5823 non-null   int64 \n 1   ident                 5823 non-null   object\n 2   actual_ident          4639 non-null   object\n 3   departuretime         5823 non-null   int64 \n 4   arrival_time          5823 non-null   int64 \n 5   origin                5823 non-null   object\n 6   destination           5823 non-null   object\n 7   aircrafttype          5373 non-null   object\n 8   meal_service          5429 non-null   object\n 9   seats_cabin_first     5823 non-null   int64 \n 10  seats_cabin_business  5823 non-null   int64 \n 11  seats_cabin_coach     5823 non-null   int64 \ndtypes: int64(6), object(6)\nmemory usage: 546.0+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(flight_schedules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 5823 rows and 12 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have an even split of numerical and string values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a quick check shows that most of our data is in mostly clean. There are a few nulls and an extra column which doesn't not need to be included. Some consideration may be needed with the nulls observed in the `actual_ident` column as it has a unique relationship to the `ident` column. We will address this during our null analysis on this dataframe. It also may be worth looking into whether the `seats_cabin_first` column is needed by checking if there are any other unique values except zero. First we will drop the `Unnamed: 0` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drops the Unnamed column in the dataframe\n",
    "def drop_unnamed(dataframe):\n",
    "    dataframe.drop(columns = 'Unnamed: 0', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_unnamed(flight_schedules) #drops the unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The unique number of seats found in the `seats_cabin_first` column of the `flight_schedules` dataframe are: [ 0 99  8 48 20 14 12]\n"
    }
   ],
   "source": [
    "print(f\"The unique number of seats found in the `seats_cabin_first` column of the `flight_schedules` dataframe are: {flight_schedules['seats_cabin_first'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows it is still worth keeping our first cabin seat count for our study as there are more that just 0 seats shown throughout the entirity of the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_analysis(dataframe):\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows whether there exist nulls in our dataframe or not:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.isnull().any()) #checks the null status of the current_flights dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"The below shows the mean of nulls existing in a dataframe:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe.isnull().mean().sort_values(ascending = False)) #checks the mean nulls in each column of the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(f\"The column with the most nulls is the '{dataframe.isnull().mean().sort_values(ascending = False).index[0]}' column with a null percentage of {dataframe.isnull().mean().sort_values(ascending = False).iloc[0]*100}%.\") #shows the highest percentage of nulls in the dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    highest_null_mask = dataframe[str(dataframe.isnull().mean().sort_values(ascending = False).index[0])].isnull() == True #creates a mask of showcasing the highest nulled column in the dataframe\n",
    "    print(\"The below shows the most masked null dataframe for more clear understanding:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe[highest_null_mask]) #shows the highest null-dataframe\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    anti_highest_null_mask = dataframe[str(dataframe.isnull().mean().sort_values(ascending = False).index[0])].isnull() == False #creates a mask of showcasing the dataframe without the highest nulled column\n",
    "    print(\"The below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\")\n",
    "    print(\" - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    print(dataframe[anti_highest_null_mask]) #shows the highest anti-null dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nident                   False\nactual_ident             True\ndeparturetime           False\narrival_time            False\norigin                  False\ndestination             False\naircrafttype             True\nmeal_service             True\nseats_cabin_first       False\nseats_cabin_business    False\nseats_cabin_coach       False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nactual_ident            0.203332\naircrafttype            0.077280\nmeal_service            0.067663\nseats_cabin_coach       0.000000\nseats_cabin_business    0.000000\nseats_cabin_first       0.000000\ndestination             0.000000\norigin                  0.000000\narrival_time            0.000000\ndeparturetime           0.000000\nident                   0.000000\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'actual_ident' column with a null percentage of 20.333161600549545%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n       ident actual_ident  departuretime  arrival_time origin destination  \\\n62    ACA572          NaN     1588347600    1588358220   CYVR        KLAX   \n64    ACA554          NaN     1588366500    1588376760   CYVR        KLAX   \n69    ACA556          NaN     1588383300    1588393920   CYVR        KLAX   \n74    ACA558          NaN     1588389000    1588399920   CYVR        KLAX   \n128   ACA572          NaN     1590179100    1590189720   CYVR        KLAX   \n...      ...          ...            ...           ...    ...         ...   \n5817  SWA993          NaN     1590458400    1590468000   KDEN        KPDX   \n5818  UAL464          NaN     1590514200    1590523860   KDEN        KPDX   \n5819  SWA378          NaN     1590520500    1590529500   KDEN        KPDX   \n5821  UAL393          NaN     1590539460    1590549120   KDEN        KPDX   \n5822  SWA993          NaN     1590544800    1590554400   KDEN        KPDX   \n\n     aircrafttype                                       meal_service  \\\n62           A320  Business: Breakfast / Economy: Breakfast, Food...   \n64           A319      Business: Meal / Economy: Food for sale, Meal   \n69           A321      Business: Meal / Economy: Food for sale, Meal   \n74           A320      Business: Meal / Economy: Food for sale, Meal   \n128          A319      Business: Meal / Economy: Food for sale, Meal   \n...           ...                                                ...   \n5817         B738                                   Economy: No meal   \n5818         A319       Business: Snack or brunch / Economy: No meal   \n5819         B738                                   Economy: No meal   \n5821         A319       Business: Snack or brunch / Economy: No meal   \n5822         B738                                   Economy: No meal   \n\n      seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n62                    0                    14                132  \n64                    0                    14                106  \n69                    0                    16                174  \n74                    0                    14                132  \n128                   0                    14                106  \n...                 ...                   ...                ...  \n5817                  0                     0                175  \n5818                  0                    12                114  \n5819                  0                     0                175  \n5821                  0                    12                114  \n5822                  0                     0                175  \n\n[1184 rows x 11 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n        ident actual_ident  departuretime  arrival_time origin destination  \\\n0     UAL4282      ASQ4282     1588330800    1588340820   CYUL        KORD   \n1     ACA7591      AC27591     1588335000    1588343880   CYUL        KORD   \n2     UAL8371      AC27591     1588335000    1588343880   CYUL        KORD   \n3     UAL4245      ASQ4245     1588341060    1588351080   CYUL        KORD   \n4     UAL8481      AC27595     1588353300    1588362000   CYUL        KORD   \n...       ...          ...            ...           ...    ...         ...   \n5808  DLH9070       UAL393     1590366660    1590376320   KDEN        KPDX   \n5812  VOI2026       FFT791     1590447900    1590457800   KDEN        KPDX   \n5815  DLH9070       UAL393     1590453060    1590462720   KDEN        KPDX   \n5816  CMP1117       UAL393     1590453060    1590462720   KDEN        KPDX   \n5820  DLH9070       UAL393     1590539460    1590549120   KDEN        KPDX   \n\n     aircrafttype                                       meal_service  \\\n0            E75L    Business: Refreshments / Economy: Food for sale   \n1            E75L  Business: Breakfast / Economy: Breakfast, Food...   \n2            E75L       Business: Breakfast / Economy: Food for sale   \n3            E75L    Business: Refreshments / Economy: Food for sale   \n4            E75L            Business: Meal / Economy: Food for sale   \n...           ...                                                ...   \n5808         A319       Business: Snack or brunch / Economy: No meal   \n5812         A320                                   Economy: No meal   \n5815         A319       Business: Snack or brunch / Economy: No meal   \n5816         A319                     Business: Meal / Economy: Meal   \n5820         A319       Business: Snack or brunch / Economy: No meal   \n\n      seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n0                     0                    12                 58  \n1                     0                    12                 64  \n2                     0                    12                 64  \n3                     0                    12                 58  \n4                     0                    12                 64  \n...                 ...                   ...                ...  \n5808                  0                    12                114  \n5812                  0                     0                186  \n5815                  0                    12                114  \n5816                  0                    12                114  \n5820                  0                    12                114  \n\n[4639 rows x 11 columns]\n"
    }
   ],
   "source": [
    "null_analysis(flight_schedules) #shows the null analysis of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not be directly obvious from the above printout and some research would be needed to explain why we are discovering nulls in the `actual_ident` column. According to [this FlightAware Discussions source](https://discussions.flightaware.com/t/airlineflightschedules-ident-and-actual-ident-not-matching/59284) which serves as a hub for FlightXML API users to discuss aspects of the API, the `actual_ident` column has a relationship with the `ident` column. In the linked thread, a FlightAware staff member by the username of \"dogrock\", responds to the general question of \"why Ident and Actual Ident are not matching?\" According to this staff member, \"if `ident` is a codeshare flight, `actual_ident` is the primary identifier used by the operator.\" Such statement is also mentioned in the documentation of the FlightXML2 documentation under the `AirlineFlightSchedules()` function. \n",
    "\n",
    "A codeshare flight is a flight where another airline purchases the route from a different airline that originally owned a route. Codeshares are business arrangements between two airlines to allow connecting flight purchases easier for customers to coordinate. [This allows an airline to market and publish a flight that isn't theres to begin with, as one of their own.](https://thepointsguy.com/guide/what-are-codeshare-flights-and-how-do-they-work/) For instance, if Delta wanted to market that they can provide service for a route from one place to another, but don't have the rights to fly that route, Delta can try establiushing a codeshare agreement with another airline who owns that route. Both airlines would come to a monetary agreement and probable resource trade that benefits both parties in such codeshare deal. Once Delta is able to purchase rights to fly a route for certain times of the year, Delta can market themselves as an adequate airline to make such a flight possible. \n",
    "\n",
    "For our purposes, it is important to keep this column and to not eliminate `actual_ident` rows. From the above, with only ~20% of `actual_ident`rows being null, most of the flights we are observing are codeshare flights. We might be able to discover some price difference in quotes if different airlines are purchasing routes from another and flying them. To bypass the nulls in this column, we will simply impute a string to erplace them and call the string `\"None\"`. This will allow python to recognize that actual string values still exist in this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_schedules['actual_ident'] = flight_schedules['actual_ident'].replace(np.nan, \"None\") #replaces NaNs with identifiable strings saying \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nident                   False\nactual_ident            False\ndeparturetime           False\narrival_time            False\norigin                  False\ndestination             False\naircrafttype             True\nmeal_service             True\nseats_cabin_first       False\nseats_cabin_business    False\nseats_cabin_coach       False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\naircrafttype            0.077280\nmeal_service            0.067663\nseats_cabin_coach       0.000000\nseats_cabin_business    0.000000\nseats_cabin_first       0.000000\ndestination             0.000000\norigin                  0.000000\narrival_time            0.000000\ndeparturetime           0.000000\nactual_ident            0.000000\nident                   0.000000\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'aircrafttype' column with a null percentage of 7.727975270479134%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n        ident actual_ident  departuretime  arrival_time origin destination  \\\n75    UAE4664      WJA1696     1588692600    1588702980   CYVR        KLAX   \n78    UAE4664      WJA1696     1588779000    1588789380   CYVR        KLAX   \n81    UAE4664      WJA1696     1588865400    1588875780   CYVR        KLAX   \n84    UAE4664      WJA1696     1588951800    1588962180   CYVR        KLAX   \n87    UAE4664      WJA1696     1589038200    1589048580   CYVR        KLAX   \n...       ...          ...            ...           ...    ...         ...   \n3597  AMX3251      EDV4708     1588332600    1588336020   KAGS        KATL   \n3606  KLM7239      EDV5332     1588359600    1588363320   KAGS        KATL   \n3607  VIR2506      EDV4790     1588368600    1588372140   KAGS        KATL   \n3608  WJA6307      EDV4790     1588368600    1588372140   KAGS        KATL   \n3609  DAL4790      EDV4790     1588368600    1588372140   KAGS        KATL   \n\n     aircrafttype      meal_service  seats_cabin_first  seats_cabin_business  \\\n75            NaN               NaN                  0                     0   \n78            NaN               NaN                  0                     0   \n81            NaN               NaN                  0                     0   \n84            NaN               NaN                  0                     0   \n87            NaN               NaN                  0                     0   \n...           ...               ...                ...                   ...   \n3597          NaN  Economy: No meal                  0                     0   \n3606          NaN  Economy: No meal                  0                     0   \n3607          NaN  Economy: No meal                  0                     0   \n3608          NaN  Economy: No meal                  0                     0   \n3609          NaN  Economy: No meal                  0                     0   \n\n      seats_cabin_coach  \n75                    0  \n78                    0  \n81                    0  \n84                    0  \n87                    0  \n...                 ...  \n3597                 64  \n3606                999  \n3607                 50  \n3608                 50  \n3609                 50  \n\n[450 rows x 11 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n        ident actual_ident  departuretime  arrival_time origin destination  \\\n0     UAL4282      ASQ4282     1588330800    1588340820   CYUL        KORD   \n1     ACA7591      AC27591     1588335000    1588343880   CYUL        KORD   \n2     UAL8371      AC27591     1588335000    1588343880   CYUL        KORD   \n3     UAL4245      ASQ4245     1588341060    1588351080   CYUL        KORD   \n4     UAL8481      AC27595     1588353300    1588362000   CYUL        KORD   \n...       ...          ...            ...           ...    ...         ...   \n5818   UAL464         None     1590514200    1590523860   KDEN        KPDX   \n5819   SWA378         None     1590520500    1590529500   KDEN        KPDX   \n5820  DLH9070       UAL393     1590539460    1590549120   KDEN        KPDX   \n5821   UAL393         None     1590539460    1590549120   KDEN        KPDX   \n5822   SWA993         None     1590544800    1590554400   KDEN        KPDX   \n\n     aircrafttype                                       meal_service  \\\n0            E75L    Business: Refreshments / Economy: Food for sale   \n1            E75L  Business: Breakfast / Economy: Breakfast, Food...   \n2            E75L       Business: Breakfast / Economy: Food for sale   \n3            E75L    Business: Refreshments / Economy: Food for sale   \n4            E75L            Business: Meal / Economy: Food for sale   \n...           ...                                                ...   \n5818         A319       Business: Snack or brunch / Economy: No meal   \n5819         B738                                   Economy: No meal   \n5820         A319       Business: Snack or brunch / Economy: No meal   \n5821         A319       Business: Snack or brunch / Economy: No meal   \n5822         B738                                   Economy: No meal   \n\n      seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n0                     0                    12                 58  \n1                     0                    12                 64  \n2                     0                    12                 64  \n3                     0                    12                 58  \n4                     0                    12                 64  \n...                 ...                   ...                ...  \n5818                  0                    12                114  \n5819                  0                     0                175  \n5820                  0                    12                114  \n5821                  0                    12                114  \n5822                  0                     0                175  \n\n[5373 rows x 11 columns]\n"
    }
   ],
   "source": [
    "null_analysis(flight_schedules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining nulls in our dataframe correspond to the `aircrafttype` and `meal_service` columns, where the largest percentage of nulls exist in our `aircrafttype` column at ~7% null. When observing the masked null dataframe above, we can see that some of nulled cells of `aircrafttype` also showcase some of the nulled cells from the `meal_service` column. In this case, we do intend to continue using the `aircrafttype` and `meal_service` columns for the modeling process as it seems these might be useful factors in determining the ticket price. With only a loss of ~7% of our dataframe plus some change from dropping the ~6% nulled rows from the `meal_service` column, we can acknowledge this loss of data as an appropriate method for proceeding with our study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_schedules.dropna(subset = ['aircrafttype', 'meal_service'], inplace = True) #drops the nulls in the aircrafttype and meal_service columns\n",
    "flight_schedules.reset_index(inplace = True) #resets the index\n",
    "flight_schedules.drop(columns = 'index', inplace = True) #drops the old index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nident                   False\nactual_ident            False\ndeparturetime           False\narrival_time            False\norigin                  False\ndestination             False\naircrafttype            False\nmeal_service            False\nseats_cabin_first       False\nseats_cabin_business    False\nseats_cabin_coach       False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nseats_cabin_coach       0.0\nseats_cabin_business    0.0\nseats_cabin_first       0.0\nmeal_service            0.0\naircrafttype            0.0\ndestination             0.0\norigin                  0.0\narrival_time            0.0\ndeparturetime           0.0\nactual_ident            0.0\nident                   0.0\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'seats_cabin_coach' column with a null percentage of 0.0%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nEmpty DataFrame\nColumns: [ident, actual_ident, departuretime, arrival_time, origin, destination, aircrafttype, meal_service, seats_cabin_first, seats_cabin_business, seats_cabin_coach]\nIndex: []\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n        ident actual_ident  departuretime  arrival_time origin destination  \\\n0     UAL4282      ASQ4282     1588330800    1588340820   CYUL        KORD   \n1     ACA7591      AC27591     1588335000    1588343880   CYUL        KORD   \n2     UAL8371      AC27591     1588335000    1588343880   CYUL        KORD   \n3     UAL4245      ASQ4245     1588341060    1588351080   CYUL        KORD   \n4     UAL8481      AC27595     1588353300    1588362000   CYUL        KORD   \n...       ...          ...            ...           ...    ...         ...   \n5054   UAL464         None     1590514200    1590523860   KDEN        KPDX   \n5055   SWA378         None     1590520500    1590529500   KDEN        KPDX   \n5056  DLH9070       UAL393     1590539460    1590549120   KDEN        KPDX   \n5057   UAL393         None     1590539460    1590549120   KDEN        KPDX   \n5058   SWA993         None     1590544800    1590554400   KDEN        KPDX   \n\n     aircrafttype                                       meal_service  \\\n0            E75L    Business: Refreshments / Economy: Food for sale   \n1            E75L  Business: Breakfast / Economy: Breakfast, Food...   \n2            E75L       Business: Breakfast / Economy: Food for sale   \n3            E75L    Business: Refreshments / Economy: Food for sale   \n4            E75L            Business: Meal / Economy: Food for sale   \n...           ...                                                ...   \n5054         A319       Business: Snack or brunch / Economy: No meal   \n5055         B738                                   Economy: No meal   \n5056         A319       Business: Snack or brunch / Economy: No meal   \n5057         A319       Business: Snack or brunch / Economy: No meal   \n5058         B738                                   Economy: No meal   \n\n      seats_cabin_first  seats_cabin_business  seats_cabin_coach  \n0                     0                    12                 58  \n1                     0                    12                 64  \n2                     0                    12                 64  \n3                     0                    12                 58  \n4                     0                    12                 64  \n...                 ...                   ...                ...  \n5054                  0                    12                114  \n5055                  0                     0                175  \n5056                  0                    12                114  \n5057                  0                    12                114  \n5058                  0                     0                175  \n\n[5059 rows x 11 columns]\n"
    }
   ],
   "source": [
    "null_analysis(flight_schedules) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we have dealt with all our nulls appropriately. Our dataframe's shape has changed to now only containing 5,059 rows now. This is a lot more data we lost than we were hoping to lose, but the intention is still to use the available information shown in the those nulled columns. There would not be any easy way of imputing the nulls in that dataframe without a more sophisticated search (or possibly through manual labor of searching the individual routes on their own). Why these nulls were present in the first place is currently unknown, but we will be able to proceed forward nonetheless. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.02 Price Data\n",
    "\n",
    "A plethora of price data was collected using the Skyscanner API. However, due to complications, some prices were found to be null for certain dates. With such limitations, lots of other data were collected to help us fill in the gaps for the missing values. We will explore both dataframes for pricing to help us analyze appropriate prices per flight. To start our cleaning process, we will re-state our `quick_check` function and re-state our key takeaways from earlier in the study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0 Quotes Places Carriers  \\\n0           0     []     []       []   \n1           1     []     []       []   \n2           2     []     []       []   \n3           3     []     []       []   \n4           4     []     []       []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n715         715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716         716                                                 []   \n717         717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718         718                                                 []   \n719         719                                                 []   \n\n                                                Places  \\\n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies ValidationErrors  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 720 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 720 entries, 0 to 719\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        720 non-null    int64 \n 1   Quotes            696 non-null    object\n 2   Places            696 non-null    object\n 3   Carriers          696 non-null    object\n 4   Currencies        696 non-null    object\n 5   ValidationErrors  24 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 33.9+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(monthly_pricing_2021) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways from the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 720 rows and 7 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking the 2021 Monthly Pricing Dataframe and Null Analysis\n",
    "\n",
    "Due to the Skyscanner's method of data scraping, our data is nested inside of dictionaries. We are going to need to clean up the dictionaries and most likely export a lot more hidden data from these dictionaries. We are prepared to create more dataframes out of these dictionaries. To make dictionary unpacking process more efficient, we are also going to have to perform a null analysis on all of the data so help us recognize any `NaNs` in our dataframe. Once such `NaNs` are recognized, we can determine what would be the most appropriate action to substitute a value for such `NaNs` OR completely eliminate them entirely based on their importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to drop the `Unnamed: 0` column through the above defined function to ease our dataframe cleaning process across multiple dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_unnamed(monthly_pricing_2021) #drops the unnamed column in the 2021 dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze how many nulls there are from the `monthly_pricing_2021` dataframe to start. This will give us some idea about the dataframe in particular and help us determine what necessary steps are needed to help us analyze our most important columns: the `Quotes` column. This will also help pave the way for handling of the similar dataframe, `june2020_to_december_2020`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes              True\nPlaces              True\nCarriers            True\nCurrencies          True\nValidationErrors    True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nValidationErrors    0.966667\nCurrencies          0.033333\nCarriers            0.033333\nPlaces              0.033333\nQuotes              0.033333\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'ValidationErrors' column with a null percentage of 96.66666666666667%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716                                                 []   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718                                                 []   \n719                                                 []   \n\n                                                Places  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies ValidationErrors  \n0    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n..                                                 ...              ...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n\n[696 rows x 5 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Quotes Places Carriers Currencies  \\\n624    NaN    NaN      NaN        NaN   \n625    NaN    NaN      NaN        NaN   \n626    NaN    NaN      NaN        NaN   \n627    NaN    NaN      NaN        NaN   \n628    NaN    NaN      NaN        NaN   \n629    NaN    NaN      NaN        NaN   \n630    NaN    NaN      NaN        NaN   \n631    NaN    NaN      NaN        NaN   \n632    NaN    NaN      NaN        NaN   \n633    NaN    NaN      NaN        NaN   \n634    NaN    NaN      NaN        NaN   \n635    NaN    NaN      NaN        NaN   \n696    NaN    NaN      NaN        NaN   \n697    NaN    NaN      NaN        NaN   \n698    NaN    NaN      NaN        NaN   \n699    NaN    NaN      NaN        NaN   \n700    NaN    NaN      NaN        NaN   \n701    NaN    NaN      NaN        NaN   \n702    NaN    NaN      NaN        NaN   \n703    NaN    NaN      NaN        NaN   \n704    NaN    NaN      NaN        NaN   \n705    NaN    NaN      NaN        NaN   \n706    NaN    NaN      NaN        NaN   \n707    NaN    NaN      NaN        NaN   \n\n                                      ValidationErrors  \n624  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n625  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n626  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n627  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n628  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n629  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n630  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n631  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n632  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n633  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n634  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n635  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n696  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n697  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n698  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n699  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n700  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n701  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n702  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n703  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n704  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n705  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n706  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n707  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n"
    }
   ],
   "source": [
    "null_analysis(monthly_pricing_2021) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, our `ValidationErrors` column contains the most nulls in our dataframe. With respect to the context of our study, keeping these `ValidationErrors` column is unnecessary as it is only an indicator for a successful query search. We will drop it from the dataframe. Before doing so, it would best to also interpret the pecentage of `ValidationErrors` nulls and comapre against the percentage nulls of the rest of the columns in our dataframe. The rest of our dataframe is presenting approximately 3.3% nulls. Through the final print statement from the above output of the dataframe, we notice that the dataframe showing values for true `ValidationErrors` is expressing nulls across the entire rows of such data. We can confidently state that the data rest of the dataframe showing nulls are missing not at random ([MNAR](https://www.theanalysisfactor.com/missing-data-mechanism/)) in this instance. We cannot identify what is triggering the validation errors in the first place through a large data scrape, but we do know the validation errors to be present for every row of `NaNs`; we know the two are related and can confidently state that for every true instance of a validation error, we can expect a row to be empty. \n",
    "\n",
    "In summary, we know that there is no need to keep the `ValidationErrors` in our study. With entire rows missing form the dataframe, we will not be able to make any meaningful identification for the missing data or find a way to impute such values. Therefore, we will drop such rows. The cost of damage for this study is minimal with only a loss of approximately 3.3% of our values. Any further errors recognized will consider this dataframe drop as a culprit, during the mass dataframe concatenation conducted in a later section (partciularly combatting an instance where a flight combination may not be read for the study).\n",
    "\n",
    "To efficiently do this, we will drop nulls across the most improtant target feature column which will shave approximately 3.3 percent of our dataframe. We will then drop the `ValidationErrors` column.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.dropna(subset = ['Quotes'], inplace = True) #drops the nulls in the dataframe pivoting off the quotes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.drop(columns = 'ValidationErrors', inplace = True) #drops the validation errors column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes        False\nPlaces        False\nCarriers      False\nCurrencies    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nCurrencies    0.0\nCarriers      0.0\nPlaces        0.0\nQuotes        0.0\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'Currencies' column with a null percentage of 0.0%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nEmpty DataFrame\nColumns: [Quotes, Places, Carriers, Currencies]\nIndex: []\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n716                                                 []   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n718                                                 []   \n719                                                 []   \n\n                                                Places  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n716                                                 []   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n718                                                 []   \n719                                                 []   \n\n                                              Carriers  \\\n0                                                   []   \n1                                                   []   \n2                                                   []   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n716                                                 []   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n718                                                 []   \n719                                                 []   \n\n                                            Currencies  \n0    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n1    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n2    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n3    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n4    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n716  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n718  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n719  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[696 rows x 4 columns]\n"
    }
   ],
   "source": [
    "null_analysis(monthly_pricing_2021) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conducting a second null_analysis on the dataframe shows that nulls no longer exist in a manner that is recognized by python. However, this does not mean we aren't missing any data. Through some of the above output, we can intuitively recognize that we are indeed missing some quotes through successful query searches. Let's analyze why python is misinterpreting such nulls. To do this, we will analyze an \"empty\" element in `monthly_pricing_2021[Quotes]` to see what python is recognizing, as well as a \"filled\" element.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "An empty element is: <class 'str'>\n- - - - - - - - - - - - - - - - - - - -\nAn empty element is: <class 'str'>\n"
    }
   ],
   "source": [
    "print(f\"An empty element is: {type(monthly_pricing_2021.loc[0, 'Quotes'])}\") #prints the type of an \"empty\" elements\n",
    "print('- - - - - - - - - - - - - - - - - - - -')\n",
    "print(f\"An empty element is: {type(monthly_pricing_2021.loc[715, 'Quotes'])}\") #prints the type of a \"filled\" element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above outputs, we can see that each element is being recognized as a string. This means the perceived \"empty\" elements are expressing a True Boolean state output. We will first replace such strings \"empty\" strings to proper `NaNs` and perform another null analysis plus drop such nulls. Then we will convert leftover \"filled\" strings to their perceived appropriate outputs with a function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021['Quotes'] = monthly_pricing_2021['Quotes'].replace(\"[]\", np.nan) #replaces the \"empty lists\" with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes         True\nPlaces        False\nCarriers      False\nCurrencies    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes        0.841954\nCurrencies    0.000000\nCarriers      0.000000\nPlaces        0.000000\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'Quotes' column with a null percentage of 84.19540229885058%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Quotes Places Carriers                                         Currencies\n0      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n1      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n2      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n3      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n4      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n..     ...    ...      ...                                                ...\n713    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n714    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n716    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n718    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n719    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n\n[586 rows x 4 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n18   [{'QuoteId': 1, 'MinPrice': 176.0, 'Direct': T...   \n24   [{'QuoteId': 1, 'MinPrice': 123.0, 'Direct': T...   \n29   [{'QuoteId': 1, 'MinPrice': 99.0, 'Direct': Tr...   \n30   [{'QuoteId': 1, 'MinPrice': 107.0, 'Direct': T...   \n31   [{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': T...   \n..                                                 ...   \n681  [{'QuoteId': 1, 'MinPrice': 351.0, 'Direct': F...   \n693  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n708  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n\n                                                Places  \\\n18   [{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...   \n24   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n29   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n30   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n31   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n..                                                 ...   \n681  [{'PlaceId': 43369, 'IataCode': 'BWI', 'Name':...   \n693  [{'PlaceId': 45623, 'IataCode': 'CVG', 'Name':...   \n708  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n18          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n24   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n29   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n30          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n31   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n..                                                 ...   \n681  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n693  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n708  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n\n                                            Currencies  \n18   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n24   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n29   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n30   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n31   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n681  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n693  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n708  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[110 rows x 4 columns]\n"
    }
   ],
   "source": [
    "null_analysis(monthly_pricing_2021) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.dropna(subset = ['Quotes'], inplace = True) #drops the recognized nulls in the Quotes column to have an effect across the entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converts the strings as literal expressions\n",
    "def as_lit_for_json(dataframe):\n",
    "    for column in dataframe.columns:\n",
    "        dataframe[column] = dataframe[column].apply(lambda element: ast.literal_eval(element)) #utilizes the ast package\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Quotes</th>\n      <th>Places</th>\n      <th>Carriers</th>\n      <th>Currencies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 176.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}]</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 123.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 99.0, 'Direct': Tr...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 107.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}]</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...</td>\n      <td>[{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 351.0, 'Direct': F...</td>\n      <td>[{'PlaceId': 43369, 'IataCode': 'BWI', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>693</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...</td>\n      <td>[{'PlaceId': 45623, 'IataCode': 'CVG', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>708</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...</td>\n      <td>[{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...</td>\n      <td>[{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...</td>\n      <td>[{'CarrierId': 1065, 'Name': 'Frontier Airline...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>[{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...</td>\n      <td>[{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...</td>\n      <td>[{'CarrierId': 851, 'Name': 'Alaska Airlines'}...</td>\n      <td>[{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>110 rows  4 columns</p>\n</div>",
      "text/plain": "                                                Quotes  \\\n18   [{'QuoteId': 1, 'MinPrice': 176.0, 'Direct': T...   \n24   [{'QuoteId': 1, 'MinPrice': 123.0, 'Direct': T...   \n29   [{'QuoteId': 1, 'MinPrice': 99.0, 'Direct': Tr...   \n30   [{'QuoteId': 1, 'MinPrice': 107.0, 'Direct': T...   \n31   [{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': T...   \n..                                                 ...   \n681  [{'QuoteId': 1, 'MinPrice': 351.0, 'Direct': F...   \n693  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n708  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n715  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n717  [{'QuoteId': 1, 'MinPrice': 120.0, 'Direct': F...   \n\n                                                Places  \\\n18   [{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...   \n24   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n29   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n30   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n31   [{'PlaceId': 65368, 'IataCode': 'LAX', 'Name':...   \n..                                                 ...   \n681  [{'PlaceId': 43369, 'IataCode': 'BWI', 'Name':...   \n693  [{'PlaceId': 45623, 'IataCode': 'CVG', 'Name':...   \n708  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n715  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n717  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n18          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n24   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n29   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n30          [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n31   [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n..                                                 ...   \n681  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n693  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n708  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n715  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n717  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n\n                                            Currencies  \n18   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n24   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n29   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n30   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n31   [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n681  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n693  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n708  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n715  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n717  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[110 rows x 4 columns]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_lit_for_json(monthly_pricing_2021) #converts the dataframe's strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect a chosen row from the dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----------------------------------------\n{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [1065], 'OriginId': 47118, 'DestinationId': 74728, 'DepartureDate': '2021-02-01T00:00:00'}, 'QuoteDateTime': '2020-06-01T13:48:00'}\n-----------------------------------------\n{'PlaceId': 47118, 'IataCode': 'DEN', 'Name': 'Denver International', 'Type': 'Station', 'SkyscannerCode': 'DEN', 'CityName': 'Denver', 'CityId': 'DENA', 'CountryName': 'United States'}\n-----------------------------------------\n{'PlaceId': 74728, 'IataCode': 'PDX', 'Name': 'Portland', 'Type': 'Station', 'SkyscannerCode': 'PDX', 'CityName': 'Portland', 'CityId': 'PDXA', 'CountryName': 'United States'}\n-----------------------------------------\n{'CarrierId': 1065, 'Name': 'Frontier Airlines'}\n-----------------------------------------\n{'Code': 'USD', 'Symbol': '$', 'ThousandsSeparator': ',', 'DecimalSeparator': '.', 'SymbolOnLeft': True, 'SpaceBetweenAmountAndSymbol': False, 'RoundingCoefficient': 0, 'DecimalDigits': 2}\n"
    }
   ],
   "source": [
    "for i in range(len(monthly_pricing_2021.loc[715])):\n",
    "    for k in range(len(monthly_pricing_2021.loc[715][i])):\n",
    "        print('-----------------------------------------')\n",
    "        print(monthly_pricing_2021.loc[715][i][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each printed element above exists within indexed row, 715 of the above dataframe. Each element is a json dictionary contained within a list. From the first element (under the `Quotes` column), all values will be considered into our new dataframe except for the `QuoteDateTime` dicitonary. \n",
    "\n",
    "For the second and third printed element (under the `Places` column), we can integrate most of the information. Keep in mind, the target dataframe will need to be integrated with the features dataframe. To do this, we will primarily utilize the `IataCode` to identify airports. \n",
    "\n",
    "The fourth printed element seems useful in that it can also provide additional airline information. This can be used to check against the flight combination airline that was originally searched. \n",
    "\n",
    "The final printed element above shows what sort of currency was returned. We are completely operating in U.S. dollars and would not require to keep such column. We will drop this column next before moving onto unpacking the dataframe. \n",
    "\n",
    "Let's drop the `Currencies` column entirely and reset the index and observe another element. This will give us a better understanding of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_pricing_2021.drop(columns = 'Currencies', inplace = True)\n",
    "monthly_pricing_2021.reset_index(inplace = True)\n",
    "monthly_pricing_2021.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect another element in our dataframe to have a better understanding of how organiz it is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----------------------------------------\n{'QuoteId': 1, 'MinPrice': 102.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [835], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-08T00:00:00'}, 'QuoteDateTime': '2020-06-02T19:46:00'}\n-----------------------------------------\n{'QuoteId': 2, 'MinPrice': 100.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [835], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-16T00:00:00'}, 'QuoteDateTime': '2020-06-02T05:41:00'}\n-----------------------------------------\n{'QuoteId': 3, 'MinPrice': 106.0, 'Direct': False, 'OutboundLeg': {'CarrierIds': [1793], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-19T00:00:00'}, 'QuoteDateTime': '2020-05-31T00:27:00'}\n-----------------------------------------\n{'QuoteId': 4, 'MinPrice': 123.0, 'Direct': True, 'OutboundLeg': {'CarrierIds': [1907], 'OriginId': 96322, 'DestinationId': 65368, 'DepartureDate': '2021-02-19T00:00:00'}, 'QuoteDateTime': '2020-05-31T00:27:00'}\n-----------------------------------------\n{'PlaceId': 65368, 'IataCode': 'LAX', 'Name': 'Los Angeles International', 'Type': 'Station', 'SkyscannerCode': 'LAX', 'CityName': 'Los Angeles', 'CityId': 'LAXA', 'CountryName': 'United States'}\n-----------------------------------------\n{'PlaceId': 96322, 'IataCode': 'YVR', 'Name': 'Vancouver International', 'Type': 'Station', 'SkyscannerCode': 'YVR', 'CityName': 'Vancouver', 'CityId': 'YVRA', 'CountryName': 'Canada'}\n-----------------------------------------\n{'CarrierId': 835, 'Name': 'Air Canada'}\n-----------------------------------------\n{'CarrierId': 1793, 'Name': 'United'}\n-----------------------------------------\n{'CarrierId': 1907, 'Name': 'WestJet'}\n"
    }
   ],
   "source": [
    "for i in range(len(monthly_pricing_2021.loc[4])):\n",
    "    for k in range(len(monthly_pricing_2021.loc[4][i])):\n",
    "        print('-----------------------------------------')\n",
    "        print(monthly_pricing_2021.loc[4][i][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see more print outputs for our new row shown at index 4. How can this be, if we dropped a column? We should bee seeing less data, no?\n",
    "\n",
    "Thoe above still showcases that we lost the unecessary currency column, but instead we are able to see a better picture of the dynamic changes in the data. In indexed row 4, there are four quotes shown with four different prices spread across three carriers. The places column seems to remain static. \n",
    "\n",
    "The focus in cleaning this data will be on generating a `quotes_2021` dataframe and storing the just the information from the Quotes column. Then we will map the `Places` information and `Carriers` information to our new quotes dataframe to finally complete our target dataframe. Such information useful to the target information can be considered as features for our feature dataframe. We do not have to worry about this being a large form of bias as we will be careful for what information we will to include (such as choosing city names).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targetframe(price_dataframe):\n",
    "    quotes = pd.DataFrame(columns = ['QuoteId', 'MinPrice', 'Direct', 'CarrierIds', 'OriginId', 'DestinationId', 'DepartureDate'])\n",
    "    places = pd.DataFrame(columns = ['PlaceId', 'IataCode', 'Name', 'CityName', 'CountryName'])\n",
    "    carriers = pd.DataFrame(columns = ['CarrierId', 'Name'])\n",
    "\n",
    "\n",
    "    ## Makes the Quotes Dataframe\n",
    "    for i in range(len(price_dataframe)):\n",
    "        for j in range(len(price_dataframe.loc[i, 'Quotes'])):\n",
    "            quoteid = price_dataframe.loc[i, 'Quotes'][j]['QuoteId']\n",
    "            minprice = price_dataframe.loc[i, 'Quotes'][j]['MinPrice']\n",
    "            direct = price_dataframe.loc[i, 'Quotes'][j]['Direct']\n",
    "            carrierid = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['CarrierIds']\n",
    "            originid = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['OriginId']\n",
    "            destinationid = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['DestinationId']\n",
    "            departuredate = price_dataframe.loc[i, 'Quotes'][j]['OutboundLeg']['DepartureDate']\n",
    "            \n",
    "            individual_quotes_dict = {'QuoteId':quoteid,\n",
    "                        'MinPrice': minprice,\n",
    "                        'Direct': direct,\n",
    "                        'CarrierIds': carrierid,\n",
    "                        'OriginId': originid,\n",
    "                        'DestinationId': destinationid,\n",
    "                        'DepartureDate': departuredate}\n",
    "            \n",
    "            individual_quotes_df = pd.DataFrame(individual_quotes_dict, columns = individual_quotes_dict.keys())\n",
    "            quotes = pd.concat([quotes, individual_quotes_df])\n",
    "\n",
    "    ## Makes the Places Dataframe\n",
    "    for i in range(len(price_dataframe)):\n",
    "        for j in range(len(price_dataframe.loc[i, 'Places'])):\n",
    "            placeid = price_dataframe.loc[i, 'Places'][j]['PlaceId']\n",
    "            iatacode = price_dataframe.loc[i, 'Places'][j]['IataCode']\n",
    "            name = price_dataframe.loc[i, 'Places'][j]['Name']\n",
    "            cityname = price_dataframe.loc[i, 'Places'][j]['CityName']\n",
    "            countryname = price_dataframe.loc[i, 'Places'][j]['CountryName']\n",
    "            \n",
    "            individual_places_dict = {'PlaceId':placeid,\n",
    "                                    'IataCode':iatacode,\n",
    "                                    'Name':name,\n",
    "                                    'CityName':cityname,\n",
    "                                    'CountryName':countryname}\n",
    "\n",
    "            individual_places_df = pd.DataFrame(individual_places_dict, columns = individual_places_dict.keys(), index = [j])\n",
    "            places = pd.concat([places, individual_places_df])\n",
    "\n",
    "\n",
    "    ## Makes the Carriers DataFrame\n",
    "    for i in range(len(price_dataframe)):\n",
    "        for j in range(len(price_dataframe.loc[i, 'Carriers'])):\n",
    "            carrierid = price_dataframe.loc[i, 'Carriers'][j]['CarrierId']\n",
    "            name = price_dataframe.loc[i, 'Carriers'][j]['Name']\n",
    "\n",
    "            individual_carriers_dict = {'CarrierId': carrierid,\n",
    "                                        'Name': name}\n",
    "            \n",
    "            individual_carriers_df = pd.DataFrame(individual_carriers_dict, columns = individual_carriers_dict.keys(), index = [j])\n",
    "            carriers = pd.concat([carriers, individual_carriers_df])\n",
    "\n",
    "\n",
    "    ## Cleans the Quotes DataFrame\n",
    "    quotes.drop_duplicates(inplace = True)\n",
    "    quotes.reset_index(inplace = True)\n",
    "    quotes.drop(columns = 'index', inplace = True)\n",
    "    quotes.rename(columns = {'CarrierIds':'CarrierId'}, inplace = True)\n",
    "\n",
    "    ## Cleans the Places Dataframe\n",
    "    places.drop_duplicates(inplace = True)\n",
    "    places.reset_index(inplace = True)\n",
    "    places.drop(columns = 'index', inplace = True)\n",
    "    places['OriginId'] = places['PlaceId']\n",
    "    places['DestinationId'] = places['PlaceId']\n",
    "    places.drop(columns = 'PlaceId', inplace = True)\n",
    "\n",
    "    ## Cleans the Carriers Dataframe\n",
    "    carriers.drop_duplicates(inplace = True)\n",
    "    carriers.reset_index(inplace = True)\n",
    "    carriers.drop(columns = 'index', inplace = True)\n",
    "    carriers.rename(columns = {'Name':'CarrierName'}, inplace = True)\n",
    "\n",
    "\n",
    "    #Merging of three dataframes\n",
    "    quotes = pd.merge(quotes, right = places, how = 'inner', on = 'OriginId')  \n",
    "    quotes.drop(columns = 'DestinationId_y', inplace = True)\n",
    "    quotes.rename(columns = {'DestinationId_x':'DestinationId', 'IataCode':'OriginIataCode','Name':'OriginName', 'CityName':'OriginCityName', 'CountryName':'OriginCountryName'}, inplace = True)\n",
    "    \n",
    "    quotes = pd.merge(quotes, right = places, how = 'inner', on = 'DestinationId')\n",
    "    quotes.drop(columns = 'OriginId_y', inplace = True)\n",
    "    quotes.rename(columns = {'OriginId_x':'OriginId', 'IataCode':'DestinationIataCode','Name':'DestinationName', 'CityName':'DestinationCityName', 'CountryName':'DestinationCountryName'}, inplace = True)\n",
    "\n",
    "    quotes = pd.merge(quotes, right = carriers, how = 'inner', on = 'CarrierId')\n",
    "   \n",
    "\n",
    "    return quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_2021 = create_targetframe(monthly_pricing_2021) #creates the 2021 quotes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QuoteId</th>\n      <th>MinPrice</th>\n      <th>Direct</th>\n      <th>CarrierId</th>\n      <th>OriginId</th>\n      <th>DestinationId</th>\n      <th>DepartureDate</th>\n      <th>OriginIataCode</th>\n      <th>OriginName</th>\n      <th>OriginCityName</th>\n      <th>OriginCountryName</th>\n      <th>DestinationIataCode</th>\n      <th>DestinationName</th>\n      <th>DestinationCityName</th>\n      <th>DestinationCountryName</th>\n      <th>CarrierName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>176.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96268</td>\n      <td>73076</td>\n      <td>2021-05-04T00:00:00</td>\n      <td>YUL</td>\n      <td>Montreal Pierre Elliott Trudeau</td>\n      <td>Montreal</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>176.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96268</td>\n      <td>73076</td>\n      <td>2021-05-15T00:00:00</td>\n      <td>YUL</td>\n      <td>Montreal Pierre Elliott Trudeau</td>\n      <td>Montreal</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>125.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96474</td>\n      <td>73076</td>\n      <td>2021-04-05T00:00:00</td>\n      <td>YYZ</td>\n      <td>Toronto Pearson International</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>125.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96474</td>\n      <td>73076</td>\n      <td>2021-04-26T00:00:00</td>\n      <td>YYZ</td>\n      <td>Toronto Pearson International</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>125.0</td>\n      <td>True</td>\n      <td>835</td>\n      <td>96474</td>\n      <td>73076</td>\n      <td>2021-05-03T00:00:00</td>\n      <td>YYZ</td>\n      <td>Toronto Pearson International</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>ORD</td>\n      <td>Chicago O'Hare International</td>\n      <td>Chicago</td>\n      <td>United States</td>\n      <td>Air Canada</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1262</th>\n      <td>3</td>\n      <td>132.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>40924</td>\n      <td>68033</td>\n      <td>2021-01-03T00:00:00</td>\n      <td>ATL</td>\n      <td>Atlanta Hartsfield-Jackson</td>\n      <td>Atlanta</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>1263</th>\n      <td>4</td>\n      <td>87.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>40924</td>\n      <td>68033</td>\n      <td>2021-01-04T00:00:00</td>\n      <td>ATL</td>\n      <td>Atlanta Hartsfield-Jackson</td>\n      <td>Atlanta</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>1264</th>\n      <td>4</td>\n      <td>112.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>42995</td>\n      <td>68033</td>\n      <td>2021-01-14T00:00:00</td>\n      <td>BOS</td>\n      <td>Boston Logan International</td>\n      <td>Boston</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>1</td>\n      <td>1509.0</td>\n      <td>True</td>\n      <td>1490</td>\n      <td>42553</td>\n      <td>74728</td>\n      <td>2021-01-07T00:00:00</td>\n      <td>BFI</td>\n      <td>Seattle Boeing Fld</td>\n      <td>Seattle</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Linear Air</td>\n    </tr>\n    <tr>\n      <th>1266</th>\n      <td>2</td>\n      <td>1509.0</td>\n      <td>True</td>\n      <td>1490</td>\n      <td>42553</td>\n      <td>74728</td>\n      <td>2021-01-08T00:00:00</td>\n      <td>BFI</td>\n      <td>Seattle Boeing Fld</td>\n      <td>Seattle</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Linear Air</td>\n    </tr>\n  </tbody>\n</table>\n<p>1267 rows  16 columns</p>\n</div>",
      "text/plain": "     QuoteId  MinPrice Direct CarrierId OriginId DestinationId  \\\n0          1     176.0   True       835    96268         73076   \n1          2     176.0   True       835    96268         73076   \n2          1     125.0   True       835    96474         73076   \n3          2     125.0   True       835    96474         73076   \n4          1     125.0   True       835    96474         73076   \n...      ...       ...    ...       ...      ...           ...   \n1262       3     132.0   True      1467    40924         68033   \n1263       4      87.0   True      1467    40924         68033   \n1264       4     112.0   True      1467    42995         68033   \n1265       1    1509.0   True      1490    42553         74728   \n1266       2    1509.0   True      1490    42553         74728   \n\n            DepartureDate OriginIataCode                       OriginName  \\\n0     2021-05-04T00:00:00            YUL  Montreal Pierre Elliott Trudeau   \n1     2021-05-15T00:00:00            YUL  Montreal Pierre Elliott Trudeau   \n2     2021-04-05T00:00:00            YYZ    Toronto Pearson International   \n3     2021-04-26T00:00:00            YYZ    Toronto Pearson International   \n4     2021-05-03T00:00:00            YYZ    Toronto Pearson International   \n...                   ...            ...                              ...   \n1262  2021-01-03T00:00:00            ATL       Atlanta Hartsfield-Jackson   \n1263  2021-01-04T00:00:00            ATL       Atlanta Hartsfield-Jackson   \n1264  2021-01-14T00:00:00            BOS       Boston Logan International   \n1265  2021-01-07T00:00:00            BFI               Seattle Boeing Fld   \n1266  2021-01-08T00:00:00            BFI               Seattle Boeing Fld   \n\n     OriginCityName OriginCountryName DestinationIataCode  \\\n0          Montreal            Canada                 ORD   \n1          Montreal            Canada                 ORD   \n2           Toronto            Canada                 ORD   \n3           Toronto            Canada                 ORD   \n4           Toronto            Canada                 ORD   \n...             ...               ...                 ...   \n1262        Atlanta     United States                 MIA   \n1263        Atlanta     United States                 MIA   \n1264         Boston     United States                 MIA   \n1265        Seattle     United States                 PDX   \n1266        Seattle     United States                 PDX   \n\n                   DestinationName DestinationCityName DestinationCountryName  \\\n0     Chicago O'Hare International             Chicago          United States   \n1     Chicago O'Hare International             Chicago          United States   \n2     Chicago O'Hare International             Chicago          United States   \n3     Chicago O'Hare International             Chicago          United States   \n4     Chicago O'Hare International             Chicago          United States   \n...                            ...                 ...                    ...   \n1262           Miami International               Miami          United States   \n1263           Miami International               Miami          United States   \n1264           Miami International               Miami          United States   \n1265                      Portland            Portland          United States   \n1266                      Portland            Portland          United States   \n\n          CarrierName  \n0          Air Canada  \n1          Air Canada  \n2          Air Canada  \n3          Air Canada  \n4          Air Canada  \n...               ...  \n1262  Spirit Airlines  \n1263  Spirit Airlines  \n1264  Spirit Airlines  \n1265       Linear Air  \n1266       Linear Air  \n\n[1267 rows x 16 columns]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataframe is the output of the quotes found in 2021, containing all useful information to help us identify which prices apply to which flight in our features dataframe. Some of the columns here will be regarded as extra features to consider for our predictions. We need not worry about what bias this may introduce as the information that will be included as features for our modeling process can also exist in the features dataframe (they were only not collected through the FlightXML2 API). Let's also note that the above size of the dataframe is 1,267 rows. This is not as many quotes as we hoped to receive and may cause us to drop some data points from our study in our features column. \n",
    "\n",
    "Our next goal will be to perform the same cleaning process onto the 2020 quotes dataframe and concat both quotes dataframes to make a large dataframe incorporating features and labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking the 2020 Monthly Pricing Dataframe and Null Analysis\n",
    "\n",
    "The 2020 monthyl pricing dataframe follows the same formatting as the 2021 monthly pricing dataframe -- which means it will require the same sort of cleaning. From what we learned from the above dataframe cleaning, we will apply the same logic to ultimately yield a `quotes_2020` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe head of your input dataframe is dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n   Unnamed: 0                                             Quotes  \\\n0           0                                                 []   \n1           1  [{'QuoteId': 1, 'MinPrice': 327.0, 'Direct': F...   \n2           2  [{'QuoteId': 1, 'MinPrice': 353.0, 'Direct': F...   \n3           3                                                 []   \n4           4                                                 []   \n\n                                              Places  \\\n0                                                 []   \n1  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n2  [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n3                                                 []   \n4                                                 []   \n\n                                   Carriers  \\\n0                                        []   \n1  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n2  [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n3                                        []   \n4                                        []   \n\n                                          Currencies ValidationErrors  \n0  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe tail of your input dataframe is:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n     Unnamed: 0                                             Quotes  \\\n415         415  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n416         416  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n417         417  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n418         418  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n419         419  [{'QuoteId': 1, 'MinPrice': 63.0, 'Direct': Tr...   \n\n                                                Places  \\\n415  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n416  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n417  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n418  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n419  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n415  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n416  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n417  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n418  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n419  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n\n                                            Currencies ValidationErrors  \n415  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n416  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n417  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n418  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n419  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n-------------------------------------------------------------------------------------------------\nThe shape of the dataframe is 420 rows and 6 columns.\n-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nUnnamed: 0          False\nQuotes               True\nPlaces               True\nCarriers             True\nCurrencies           True\nValidationErrors     True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the useful information to be aware of when exploring this input dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 420 entries, 0 to 419\nData columns (total 6 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   Unnamed: 0        420 non-null    int64 \n 1   Quotes            406 non-null    object\n 2   Places            406 non-null    object\n 3   Carriers          406 non-null    object\n 4   Currencies        406 non-null    object\n 5   ValidationErrors  14 non-null     object\ndtypes: int64(1), object(5)\nmemory usage: 19.8+ KB\nNone\n"
    }
   ],
   "source": [
    "quick_check(june2020_to_december2020_monthlyprice) #performs a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key takeaways fromm the above output:\n",
    "\n",
    "- The dataframe is large and denotes separations with a `\\` symbol.\n",
    "\n",
    "- The data is stored in json dictionaries. We will need to clean that to access more readable data.\n",
    "\n",
    "- There is an `Unnamed: 0` column in our dataframe which is not necessary to include. We will remove this in our cleaning.\n",
    "\n",
    "- Our dataframe is 5823 rows and 6 columns.\n",
    "\n",
    "- Our dataframe contains nulls. \n",
    "\n",
    "- We have mostly string values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes              True\nPlaces              True\nCarriers            True\nCurrencies          True\nValidationErrors    True\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nValidationErrors    0.966667\nCurrencies          0.033333\nCarriers            0.033333\nPlaces              0.033333\nQuotes              0.033333\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'ValidationErrors' column with a null percentage of 96.66666666666667%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n0                                                   []   \n1    [{'QuoteId': 1, 'MinPrice': 327.0, 'Direct': F...   \n2    [{'QuoteId': 1, 'MinPrice': 353.0, 'Direct': F...   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n415  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n416  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n417  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n418  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n419  [{'QuoteId': 1, 'MinPrice': 63.0, 'Direct': Tr...   \n\n                                                Places  \\\n0                                                   []   \n1    [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n2    [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n415  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n416  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n417  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n418  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n419  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n0                                                   []   \n1             [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n2             [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n415  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n416  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n417  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n418  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n419  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n\n                                            Currencies ValidationErrors  \n0    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n1    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n2    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n3    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n4    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n..                                                 ...              ...  \n415  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n416  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n417  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n418  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n419  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...              NaN  \n\n[406 rows x 5 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Quotes Places Carriers Currencies  \\\n364    NaN    NaN      NaN        NaN   \n365    NaN    NaN      NaN        NaN   \n366    NaN    NaN      NaN        NaN   \n367    NaN    NaN      NaN        NaN   \n368    NaN    NaN      NaN        NaN   \n369    NaN    NaN      NaN        NaN   \n370    NaN    NaN      NaN        NaN   \n406    NaN    NaN      NaN        NaN   \n407    NaN    NaN      NaN        NaN   \n408    NaN    NaN      NaN        NaN   \n409    NaN    NaN      NaN        NaN   \n410    NaN    NaN      NaN        NaN   \n411    NaN    NaN      NaN        NaN   \n412    NaN    NaN      NaN        NaN   \n\n                                      ValidationErrors  \n364  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n365  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n366  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n367  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n368  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n369  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n370  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n406  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n407  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n408  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n409  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n410  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n411  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n412  [{'ParameterName': 'OriginPlace', 'ParameterVa...  \n"
    }
   ],
   "source": [
    "drop_unnamed(june2020_to_december2020_monthlyprice) #drops the unnamed column in the 2020 dataframne\n",
    "null_analysis(june2020_to_december2020_monthlyprice) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes        False\nPlaces        False\nCarriers      False\nCurrencies    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nCurrencies    0.0\nCarriers      0.0\nPlaces        0.0\nQuotes        0.0\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'Currencies' column with a null percentage of 0.0%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nEmpty DataFrame\nColumns: [Quotes, Places, Carriers, Currencies]\nIndex: []\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n0                                                   []   \n1    [{'QuoteId': 1, 'MinPrice': 327.0, 'Direct': F...   \n2    [{'QuoteId': 1, 'MinPrice': 353.0, 'Direct': F...   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n415  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n416  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n417  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n418  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n419  [{'QuoteId': 1, 'MinPrice': 63.0, 'Direct': Tr...   \n\n                                                Places  \\\n0                                                   []   \n1    [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n2    [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n415  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n416  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n417  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n418  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n419  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n0                                                   []   \n1             [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n2             [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n3                                                   []   \n4                                                   []   \n..                                                 ...   \n415  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n416  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n417  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n418  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n419  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n\n                                            Currencies  \n0    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n1    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n2    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n3    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n4    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n415  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n416  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n417  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n418  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n419  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[406 rows x 4 columns]\n"
    }
   ],
   "source": [
    "june2020_to_december2020_monthlyprice.dropna(subset = ['Quotes'], inplace = True) #drops the nulls in the dataframe pivoting off the quotes column\n",
    "june2020_to_december2020_monthlyprice.drop(columns = 'ValidationErrors', inplace = True) #drops the validation errors column\n",
    "null_analysis(june2020_to_december2020_monthlyprice) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-------------------------------------------------------------------------------------------------\nThe below shows whether there exist nulls in our dataframe or not:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes         True\nPlaces        False\nCarriers      False\nCurrencies    False\ndtype: bool\n-------------------------------------------------------------------------------------------------\nThe below shows the mean of nulls existing in a dataframe:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nQuotes        0.342365\nCurrencies    0.000000\nCarriers      0.000000\nPlaces        0.000000\ndtype: float64\n-------------------------------------------------------------------------------------------------\nThe column with the most nulls is the 'Quotes' column with a null percentage of 34.23645320197045%.\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n    Quotes Places Carriers                                         Currencies\n0      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n3      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n4      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n5      NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n12     NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n..     ...    ...      ...                                                ...\n363    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n371    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n373    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n376    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n399    NaN     []       []  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...\n\n[139 rows x 4 columns]\n-------------------------------------------------------------------------------------------------\nThe below shows the most masked null dataframe, where nulls are filtered out, for more clear understanding:\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n                                                Quotes  \\\n1    [{'QuoteId': 1, 'MinPrice': 327.0, 'Direct': F...   \n2    [{'QuoteId': 1, 'MinPrice': 353.0, 'Direct': F...   \n6    [{'QuoteId': 1, 'MinPrice': 328.0, 'Direct': F...   \n7    [{'QuoteId': 1, 'MinPrice': 175.0, 'Direct': T...   \n8    [{'QuoteId': 1, 'MinPrice': 174.0, 'Direct': F...   \n..                                                 ...   \n415  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n416  [{'QuoteId': 1, 'MinPrice': 79.0, 'Direct': Tr...   \n417  [{'QuoteId': 1, 'MinPrice': 199.0, 'Direct': T...   \n418  [{'QuoteId': 1, 'MinPrice': 69.0, 'Direct': Tr...   \n419  [{'QuoteId': 1, 'MinPrice': 63.0, 'Direct': Tr...   \n\n                                                Places  \\\n1    [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n2    [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n6    [{'PlaceId': 60987, 'IataCode': 'JFK', 'Name':...   \n7    [{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...   \n8    [{'PlaceId': 73076, 'IataCode': 'ORD', 'Name':...   \n..                                                 ...   \n415  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n416  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n417  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n418  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n419  [{'PlaceId': 47118, 'IataCode': 'DEN', 'Name':...   \n\n                                              Carriers  \\\n1             [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n2             [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n6             [{'CarrierId': 1907, 'Name': 'WestJet'}]   \n7           [{'CarrierId': 835, 'Name': 'Air Canada'}]   \n8    [{'CarrierId': 835, 'Name': 'Air Canada'}, {'C...   \n..                                                 ...   \n415  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n416  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n417  [{'CarrierId': 851, 'Name': 'Alaska Airlines'}...   \n418  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n419  [{'CarrierId': 1065, 'Name': 'Frontier Airline...   \n\n                                            Currencies  \n1    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n2    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n6    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n7    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n8    [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n..                                                 ...  \n415  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n416  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n417  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n418  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n419  [{'Code': 'USD', 'Symbol': '$', 'ThousandsSepa...  \n\n[267 rows x 4 columns]\n"
    }
   ],
   "source": [
    "june2020_to_december2020_monthlyprice['Quotes'] = june2020_to_december2020_monthlyprice['Quotes'].replace(\"[]\", np.nan) #replaces the \"empty lists\" with NaNs\n",
    "null_analysis(june2020_to_december2020_monthlyprice) #performs a null analysis on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "june2020_to_december2020_monthlyprice.dropna(subset = ['Quotes'], inplace = True) #drops the recognized nulls in the Quotes column to have an effect across the entire dataframe\n",
    "as_lit_for_json(june2020_to_december2020_monthlyprice) #converts the dataframe's strings\n",
    "june2020_to_december2020_monthlyprice.drop(columns = 'Currencies', inplace = True)\n",
    "june2020_to_december2020_monthlyprice.reset_index(inplace = True)\n",
    "june2020_to_december2020_monthlyprice.drop(columns = 'index', inplace = True)\n",
    "quotes_2020 = create_targetframe(june2020_to_december2020_monthlyprice) #creates the 2020 quotes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QuoteId</th>\n      <th>MinPrice</th>\n      <th>Direct</th>\n      <th>CarrierId</th>\n      <th>OriginId</th>\n      <th>DestinationId</th>\n      <th>DepartureDate</th>\n      <th>OriginIataCode</th>\n      <th>OriginName</th>\n      <th>OriginCityName</th>\n      <th>OriginCountryName</th>\n      <th>DestinationIataCode</th>\n      <th>DestinationName</th>\n      <th>DestinationCityName</th>\n      <th>DestinationCountryName</th>\n      <th>CarrierName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>327.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-05T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>327.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-06T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>328.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-07T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>328.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-09T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>330.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-10T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5078</th>\n      <td>2</td>\n      <td>120.0</td>\n      <td>False</td>\n      <td>1721</td>\n      <td>43369</td>\n      <td>74728</td>\n      <td>2020-09-03T00:00:00</td>\n      <td>BWI</td>\n      <td>Baltimore Washington International</td>\n      <td>Washington</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Sun Country Airlines</td>\n    </tr>\n    <tr>\n      <th>5079</th>\n      <td>3</td>\n      <td>120.0</td>\n      <td>False</td>\n      <td>1721</td>\n      <td>43369</td>\n      <td>74728</td>\n      <td>2020-09-04T00:00:00</td>\n      <td>BWI</td>\n      <td>Baltimore Washington International</td>\n      <td>Washington</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Sun Country Airlines</td>\n    </tr>\n    <tr>\n      <th>5080</th>\n      <td>4</td>\n      <td>125.0</td>\n      <td>False</td>\n      <td>1721</td>\n      <td>43369</td>\n      <td>74728</td>\n      <td>2020-09-06T00:00:00</td>\n      <td>BWI</td>\n      <td>Baltimore Washington International</td>\n      <td>Washington</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Sun Country Airlines</td>\n    </tr>\n    <tr>\n      <th>5081</th>\n      <td>5</td>\n      <td>125.0</td>\n      <td>False</td>\n      <td>1721</td>\n      <td>43369</td>\n      <td>74728</td>\n      <td>2020-09-07T00:00:00</td>\n      <td>BWI</td>\n      <td>Baltimore Washington International</td>\n      <td>Washington</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Sun Country Airlines</td>\n    </tr>\n    <tr>\n      <th>5082</th>\n      <td>5</td>\n      <td>165.0</td>\n      <td>False</td>\n      <td>1721</td>\n      <td>43369</td>\n      <td>74728</td>\n      <td>2020-10-25T00:00:00</td>\n      <td>BWI</td>\n      <td>Baltimore Washington International</td>\n      <td>Washington</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Sun Country Airlines</td>\n    </tr>\n  </tbody>\n</table>\n<p>5083 rows  16 columns</p>\n</div>",
      "text/plain": "     QuoteId  MinPrice Direct CarrierId OriginId DestinationId  \\\n0          1     327.0  False      1907    95645         60987   \n1          2     327.0  False      1907    95645         60987   \n2          3     328.0  False      1907    95645         60987   \n3          4     328.0  False      1907    95645         60987   \n4          5     330.0  False      1907    95645         60987   \n...      ...       ...    ...       ...      ...           ...   \n5078       2     120.0  False      1721    43369         74728   \n5079       3     120.0  False      1721    43369         74728   \n5080       4     125.0  False      1721    43369         74728   \n5081       5     125.0  False      1721    43369         74728   \n5082       5     165.0  False      1721    43369         74728   \n\n            DepartureDate OriginIataCode                          OriginName  \\\n0     2020-07-05T00:00:00            YHM                            Hamilton   \n1     2020-07-06T00:00:00            YHM                            Hamilton   \n2     2020-07-07T00:00:00            YHM                            Hamilton   \n3     2020-07-09T00:00:00            YHM                            Hamilton   \n4     2020-07-10T00:00:00            YHM                            Hamilton   \n...                   ...            ...                                 ...   \n5078  2020-09-03T00:00:00            BWI  Baltimore Washington International   \n5079  2020-09-04T00:00:00            BWI  Baltimore Washington International   \n5080  2020-09-06T00:00:00            BWI  Baltimore Washington International   \n5081  2020-09-07T00:00:00            BWI  Baltimore Washington International   \n5082  2020-10-25T00:00:00            BWI  Baltimore Washington International   \n\n     OriginCityName OriginCountryName DestinationIataCode  \\\n0           Toronto            Canada                 JFK   \n1           Toronto            Canada                 JFK   \n2           Toronto            Canada                 JFK   \n3           Toronto            Canada                 JFK   \n4           Toronto            Canada                 JFK   \n...             ...               ...                 ...   \n5078     Washington     United States                 PDX   \n5079     Washington     United States                 PDX   \n5080     Washington     United States                 PDX   \n5081     Washington     United States                 PDX   \n5082     Washington     United States                 PDX   \n\n               DestinationName DestinationCityName DestinationCountryName  \\\n0     New York John F. Kennedy            New York          United States   \n1     New York John F. Kennedy            New York          United States   \n2     New York John F. Kennedy            New York          United States   \n3     New York John F. Kennedy            New York          United States   \n4     New York John F. Kennedy            New York          United States   \n...                        ...                 ...                    ...   \n5078                  Portland            Portland          United States   \n5079                  Portland            Portland          United States   \n5080                  Portland            Portland          United States   \n5081                  Portland            Portland          United States   \n5082                  Portland            Portland          United States   \n\n               CarrierName  \n0                  WestJet  \n1                  WestJet  \n2                  WestJet  \n3                  WestJet  \n4                  WestJet  \n...                    ...  \n5078  Sun Country Airlines  \n5079  Sun Country Airlines  \n5080  Sun Country Airlines  \n5081  Sun Country Airlines  \n5082  Sun Country Airlines  \n\n[5083 rows x 16 columns]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see the final output for the cleaning of the 2020 pricing data (from June until December). There seems to be much more data collected in a shorter timespan in 2020 than there was for 2021. This will create some imbalance in the legitimacy of our study. Even more importantly, there is not enough data collected on the pricing as it is much smaller than the flight data collected. This too may play a role in the amount of data that will be generated altogether when both dataframes are finally combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the Pricing Data into One Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>QuoteId</th>\n      <th>MinPrice</th>\n      <th>Direct</th>\n      <th>CarrierId</th>\n      <th>OriginId</th>\n      <th>DestinationId</th>\n      <th>DepartureDate</th>\n      <th>OriginIataCode</th>\n      <th>OriginName</th>\n      <th>OriginCityName</th>\n      <th>OriginCountryName</th>\n      <th>DestinationIataCode</th>\n      <th>DestinationName</th>\n      <th>DestinationCityName</th>\n      <th>DestinationCountryName</th>\n      <th>CarrierName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>327.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-05T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>327.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-06T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>328.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-07T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>328.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-09T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>330.0</td>\n      <td>False</td>\n      <td>1907</td>\n      <td>95645</td>\n      <td>60987</td>\n      <td>2020-07-10T00:00:00</td>\n      <td>YHM</td>\n      <td>Hamilton</td>\n      <td>Toronto</td>\n      <td>Canada</td>\n      <td>JFK</td>\n      <td>New York John F. Kennedy</td>\n      <td>New York</td>\n      <td>United States</td>\n      <td>WestJet</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6345</th>\n      <td>1262</td>\n      <td>3</td>\n      <td>132.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>40924</td>\n      <td>68033</td>\n      <td>2021-01-03T00:00:00</td>\n      <td>ATL</td>\n      <td>Atlanta Hartsfield-Jackson</td>\n      <td>Atlanta</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>6346</th>\n      <td>1263</td>\n      <td>4</td>\n      <td>87.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>40924</td>\n      <td>68033</td>\n      <td>2021-01-04T00:00:00</td>\n      <td>ATL</td>\n      <td>Atlanta Hartsfield-Jackson</td>\n      <td>Atlanta</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>6347</th>\n      <td>1264</td>\n      <td>4</td>\n      <td>112.0</td>\n      <td>True</td>\n      <td>1467</td>\n      <td>42995</td>\n      <td>68033</td>\n      <td>2021-01-14T00:00:00</td>\n      <td>BOS</td>\n      <td>Boston Logan International</td>\n      <td>Boston</td>\n      <td>United States</td>\n      <td>MIA</td>\n      <td>Miami International</td>\n      <td>Miami</td>\n      <td>United States</td>\n      <td>Spirit Airlines</td>\n    </tr>\n    <tr>\n      <th>6348</th>\n      <td>1265</td>\n      <td>1</td>\n      <td>1509.0</td>\n      <td>True</td>\n      <td>1490</td>\n      <td>42553</td>\n      <td>74728</td>\n      <td>2021-01-07T00:00:00</td>\n      <td>BFI</td>\n      <td>Seattle Boeing Fld</td>\n      <td>Seattle</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Linear Air</td>\n    </tr>\n    <tr>\n      <th>6349</th>\n      <td>1266</td>\n      <td>2</td>\n      <td>1509.0</td>\n      <td>True</td>\n      <td>1490</td>\n      <td>42553</td>\n      <td>74728</td>\n      <td>2021-01-08T00:00:00</td>\n      <td>BFI</td>\n      <td>Seattle Boeing Fld</td>\n      <td>Seattle</td>\n      <td>United States</td>\n      <td>PDX</td>\n      <td>Portland</td>\n      <td>Portland</td>\n      <td>United States</td>\n      <td>Linear Air</td>\n    </tr>\n  </tbody>\n</table>\n<p>6350 rows  17 columns</p>\n</div>",
      "text/plain": "      index QuoteId  MinPrice Direct CarrierId OriginId DestinationId  \\\n0         0       1     327.0  False      1907    95645         60987   \n1         1       2     327.0  False      1907    95645         60987   \n2         2       3     328.0  False      1907    95645         60987   \n3         3       4     328.0  False      1907    95645         60987   \n4         4       5     330.0  False      1907    95645         60987   \n...     ...     ...       ...    ...       ...      ...           ...   \n6345   1262       3     132.0   True      1467    40924         68033   \n6346   1263       4      87.0   True      1467    40924         68033   \n6347   1264       4     112.0   True      1467    42995         68033   \n6348   1265       1    1509.0   True      1490    42553         74728   \n6349   1266       2    1509.0   True      1490    42553         74728   \n\n            DepartureDate OriginIataCode                  OriginName  \\\n0     2020-07-05T00:00:00            YHM                    Hamilton   \n1     2020-07-06T00:00:00            YHM                    Hamilton   \n2     2020-07-07T00:00:00            YHM                    Hamilton   \n3     2020-07-09T00:00:00            YHM                    Hamilton   \n4     2020-07-10T00:00:00            YHM                    Hamilton   \n...                   ...            ...                         ...   \n6345  2021-01-03T00:00:00            ATL  Atlanta Hartsfield-Jackson   \n6346  2021-01-04T00:00:00            ATL  Atlanta Hartsfield-Jackson   \n6347  2021-01-14T00:00:00            BOS  Boston Logan International   \n6348  2021-01-07T00:00:00            BFI          Seattle Boeing Fld   \n6349  2021-01-08T00:00:00            BFI          Seattle Boeing Fld   \n\n     OriginCityName OriginCountryName DestinationIataCode  \\\n0           Toronto            Canada                 JFK   \n1           Toronto            Canada                 JFK   \n2           Toronto            Canada                 JFK   \n3           Toronto            Canada                 JFK   \n4           Toronto            Canada                 JFK   \n...             ...               ...                 ...   \n6345        Atlanta     United States                 MIA   \n6346        Atlanta     United States                 MIA   \n6347         Boston     United States                 MIA   \n6348        Seattle     United States                 PDX   \n6349        Seattle     United States                 PDX   \n\n               DestinationName DestinationCityName DestinationCountryName  \\\n0     New York John F. Kennedy            New York          United States   \n1     New York John F. Kennedy            New York          United States   \n2     New York John F. Kennedy            New York          United States   \n3     New York John F. Kennedy            New York          United States   \n4     New York John F. Kennedy            New York          United States   \n...                        ...                 ...                    ...   \n6345       Miami International               Miami          United States   \n6346       Miami International               Miami          United States   \n6347       Miami International               Miami          United States   \n6348                  Portland            Portland          United States   \n6349                  Portland            Portland          United States   \n\n          CarrierName  \n0             WestJet  \n1             WestJet  \n2             WestJet  \n3             WestJet  \n4             WestJet  \n...               ...  \n6345  Spirit Airlines  \n6346  Spirit Airlines  \n6347  Spirit Airlines  \n6348       Linear Air  \n6349       Linear Air  \n\n[6350 rows x 17 columns]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes = pd.concat([quotes_2020, quotes_2021]) #concats both pricing dataframes to make one target dataframe\n",
    "quotes.reset_index(inplace = True) #resets the index of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output dataframe shows the combined quotes dtaaframe showcasing prices from 2020 and 2021 for our flight combinations. This is our final target datafram,e which will be used to integrate into our features dataframe and create an ultimate dataframe to help us conduct a model for predictions. The combined total of data in our dataframe is 6,350 rows. THis is much less than anticipated for the study, which expresses the limitations faced with the Skyscanner API and the limitations possibly faces on flights in the future due to the pandemic. Further reason for error can also stem from the fact that such flight combinations do not exist for future instances or have not been schedules yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.03 Other Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.04 Creating the Model Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Future Work\n",
    "\n",
    "For the future, consider incorporating weather data, randomized passenger weight data, incorporate the dynamic changes in fuel/mass ratio throughout a flight, incorporate some demographical passenger data, more routes, the ability for the problem to become a UI tool rather than just a study."
   ]
  }
 ]
}